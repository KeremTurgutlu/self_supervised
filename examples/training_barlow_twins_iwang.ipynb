{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimCLR ImageWang Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This notebook demonstrates how to use `SimCLR` callback with a single GPU. For distributed version, `DistributedSimCLR` checkout documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import **fastai** for training and other helpers, you can choose not to use **wandb** by setting `WANDB=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "import wandb\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "WANDB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import **self_supervised** `augmentations` module for creating augmentations pipeline, `layers` module for creating encoder and model, and finally `simclr` for self-supervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "# from self_supervised.vision.simclr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will take a look at [ImageWang](https://github.com/fastai/imagenette#image%E7%BD%91) benchmark, how to train a self-supervised model using MoCo algorithm and then how to use this pretrained model for finetuning on the given downstream task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(size, bs, workers=None):\n",
    "    path = URLs.IMAGEWANG_160 if size <= 160 else URLs.IMAGEWANG\n",
    "    source = untar_data(path)\n",
    "    \n",
    "    files = get_image_files(source)\n",
    "    tfms = [[PILImage.create, ToTensor, RandomResizedCrop(size, min_scale=1.)], \n",
    "            [parent_label, Categorize()]]\n",
    "    \n",
    "    dsets = Datasets(files, tfms=tfms, splits=RandomSplitter(valid_pct=0.1)(files))\n",
    "    \n",
    "    batch_tfms = [IntToFloatTensor]\n",
    "    dls = dsets.dataloaders(bs=bs, num_workers=workers, after_batch=batch_tfms)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageWang has several benchmarks for different image sizes, in this tutorial we will go for `size=224` and also demonstrate how effectively you can utilize GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batch size, resize resolution before batching and size for random cropping during self-supervised training. It's always good to use a batch size as high as it can fit the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, resize, size = 256, 256, 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select architecture to train on, remember all **timm** and **fastai** models are available! We need to set `pretrained=False` here because using imagenet weights for ImageWang data would be cheating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"xresnet34\"\n",
    "encoder = create_encoder(arch, pretrained=False, n_in=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WANDB:\n",
    "    xtra_config = {\"Arch\":arch, \"Resize\":resize, \"Size\":size, \"Algorithm\":\"SWAV\"}\n",
    "    wandb.init(project=\"self-supervised-imagewang\", config=xtra_config);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Dataloaders using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(resize, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SimCLR model. You can change values of `hidden_size`, `projection_size`, and `n_layers`. For this problem, defaults work just fine so we don't do any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwinsModel(Module):\n",
    "    \"An encoder followed by a projector\" \n",
    "    def __init__(self,encoder,projector): self.encoder,self.projector = encoder,projector\n",
    "    def forward(self,x): return self.projector(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_barlow_twins_model(encoder, hidden_size=256, projection_size=128, nlayers=3):\n",
    "    \"Create SimCLR model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=True, nlayers=3) \n",
    "    apply_init(projector)\n",
    "    return BarlowTwinsModel(encoder, projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_barlow_twins_model(encoder, hidden_size=768, projection_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (4): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is perhaps the most critical step for achieving good results on a custom problem - data augmentation. For this, we will use utility function from `self_supervised.vision.simclr.get_simclr_aug_pipelines` but you can also use your own list of Pipeline augmentations. `self_supervised.vision.simclr.get_moco_aug_pipelines`should be enough for most of the cases since under the hood it uses `self_supervised.augmentations.get_multi_aug_pipelines` and `self_supervised.augmentations.get_batch_augs`. You can do shift+tab and see all the arguments that can be passed to `get_simclr_aug_pipelines`. You can simply pass anything that you could pass to `get_batch_augs` including custom `xtra_tfms`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_simclr_aug_pipelines` excepts size for random resized cropping of the 2 views of a given image and the rest of the arguments are coming from `get_batch_augs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pipelines = get_multi_aug_pipelines(n=2, size=size, rotate=True, \n",
    "                                        rotate_deg=10, jitter=True, bw=True, blur=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> ColorJitter -> RandomGrayscale -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
       " \n",
       "          [[0.4560]],\n",
       " \n",
       "          [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
       " \n",
       "          [[0.2240]],\n",
       " \n",
       "          [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)},\n",
       " Pipeline: RandomResizedCrop -> RandomHorizontalFlip -> ColorJitter -> RandomGrayscale -> Rotate -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 1.0} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
       " \n",
       "          [[0.4560]],\n",
       " \n",
       "          [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
       " \n",
       "          [[0.2240]],\n",
       " \n",
       "          [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will feed the augmentation pipelines and leave temperature parameter as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BarlowTwins(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, lmb=0.1, print_augs=False):\n",
    "        assert_aug_pipelines(aug_pipelines)\n",
    "        self.aug1, self.aug2 = aug_pipelines\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        store_attr('lmb')\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        nf = self.learn.model.projector[-1].out_features\n",
    "        self.I = torch.eye(nf).to(self.dls.device)\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        \n",
    "    \n",
    "    def lf(self, pred, *yb):\n",
    "        bs,nf = pred.size(0)//2,pred.size(1)\n",
    "        z1, z2 = pred[:bs],pred[bs:]\n",
    "        \n",
    "        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)\n",
    "        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)\n",
    "        \n",
    "        C = (z1norm.T @ z2norm) / bs \n",
    "        cdiff = (C - self.I)**2\n",
    "        loss = (cdiff*self.I + cdiff*(1-self.I)*self.lmb).sum() \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = self.learn.x[:bs], self.learn.x[bs:] \n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs=[BarlowTwins(aug_pipelines, lmb=0.1)]\n",
    "if WANDB: cbs += [WandbCallback(log_preds=False,log_model=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, cbs=cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting training let's check whether our augmentations makes sense or not. Since this step consumes GPU memory, once you are done with inspection, restart the notebook and skip this step. We can see that 2 views of the same image side by side and indeed augmentations look pretty good. Now, it's time restart the notebook and skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# learn._split(b)\n",
    "# learn('before_batch')\n",
    "# learn.sim_clr.show(n=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use mixed precision with `to_fp16()` for more GPU memory, larger batch size and faster training . We could also use gradient checkpointing wrapper models from `self_supervised.layers` to save even more memory, e.g. `CheckpointSequential()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning good representations via contrastive learning usually takes a lot of epochs. So here number epochs are set to 100. This might change depending on your data distribution and dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr,wd,epochs=1e-2,1e-2,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/100 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.04% [12/92 00:18<02:04 1229.1421]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_flat_cos(epochs, lr, wd=wd, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WANDB: wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = f'simclr_iwang_sz{size}_epc{epochs}'\n",
    "learn.save(save_name)\n",
    "torch.save(learn.model.encoder.state_dict(), learn.path/learn.model_dir/f'{save_name}_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdict = dict(sqrmom=0.99,mom=0.95,beta=0.,eps=1e-4)\n",
    "opt_func = partial(ranger, **optdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(size, bs, workers=None):\n",
    "    path = URLs.IMAGEWANG_160 if size <= 160 else URLs.IMAGEWANG\n",
    "    source = untar_data(path)\n",
    "    files = get_image_files(source, folders=['train', 'val'])\n",
    "    splits = GrandparentSplitter(valid_name='val')(files)\n",
    "    \n",
    "    item_aug = [RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)]\n",
    "    tfms = [[PILImage.create, ToTensor, *item_aug], \n",
    "            [parent_label, Categorize()]]\n",
    "    \n",
    "    dsets = Datasets(files, tfms=tfms, splits=splits)\n",
    "    \n",
    "    batch_tfms = [IntToFloatTensor, Normalize.from_stats(*imagenet_stats)]\n",
    "    dls = dsets.dataloaders(bs=bs, num_workers=workers, after_batch=batch_tfms)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_func(m): return L(m[0], m[1]).map(params)\n",
    "\n",
    "def create_learner(size=size, arch='xresnet34', encoder_path=\"models/swav_iwang_sz128_epc100_encoder.pth\"):\n",
    "    \n",
    "    dls = get_dls(size, bs=bs//2)\n",
    "    pretrained_encoder = torch.load(encoder_path)\n",
    "    encoder = create_encoder(arch, pretrained=False, n_in=3)\n",
    "    encoder.load_state_dict(pretrained_encoder)\n",
    "    nf = encoder(torch.randn(2,3,224,224)).size(-1)\n",
    "    classifier = create_cls_module(nf, dls.c)\n",
    "    model = nn.Sequential(encoder, classifier)\n",
    "    learn = Learner(dls, model, opt_func=opt_func, splitter=split_func,\n",
    "                metrics=[accuracy,top_k_accuracy], loss_func=LabelSmoothingCrossEntropy())\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(size, epochs, arch, encoder_path, lr=1e-2, wd=1e-2):\n",
    "    learn = create_learner(size, arch, encoder_path)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_flat_cos(epochs, lr, wd=wd)\n",
    "    final_acc = learn.recorder.values[-1][-2]\n",
    "    return final_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "runs = 5\n",
    "for i in range(runs): acc += [finetune(size, epochs=5, arch='xresnet34', encoder_path=f'models/simclr_iwang_sz{size}_epc100_encoder.pth')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "runs = 3\n",
    "for i in range(runs): acc += [finetune(size, epochs=20, arch='xresnet34', encoder_path=f'models/simclr_iwang_sz{size}_epc100_encoder.pth')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "runs = 1\n",
    "for i in range(runs): acc += [finetune(size, epochs=80, arch='xresnet34',encoder_path=f'models/simclr_iwang_sz{size}_epc100_encoder.pth')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "runs = 1\n",
    "for i in range(runs): acc += [finetune(size, epochs=200, arch='xresnet34', encoder_path=f'models/simclr_iwang_sz{size}_epc100_encoder.pth')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
