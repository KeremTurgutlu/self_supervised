---

title: CLIP-MoCo


keywords: fastai
sidebar: home_sidebar

summary: "**CLIP**: <a href='https://arxiv.org/pdf/2103.00020.pdf'>Learning Transferable Visual Models From Natural Language Supervision</a>"
description: "**CLIP**: <a href='https://arxiv.org/pdf/2103.00020.pdf'>Learning Transferable Visual Models From Natural Language Supervision</a>"
nb_path: "nbs/21 - clip-moco.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/21 - clip-moco.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This module combines CLIP and MoCo for increasing negative samples. This is useful when there is no available compute such as GPUs with large memory to support large batch sizes or multi-gpu machines to leverage distributed infonce loss implementation.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Algorithm">Algorithm<a class="anchor-link" href="#Algorithm"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="CLIP">CLIP<a class="anchor-link" href="#CLIP"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/self_supervised/images/clip.png" alt="CLIP"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="MoCo">MoCo<a class="anchor-link" href="#MoCo"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/self_supervised/images/moco.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tokenizer">Tokenizer<a class="anchor-link" href="#Tokenizer"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ClipTokenizer" class="doc_header"><code>class</code> <code>ClipTokenizer</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L23" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ClipTokenizer</code>(<strong><code>context_length</code></strong>=<em><code>77</code></em>) :: <code>DisplayedTransform</code></p>
</blockquote>
<p>Tokenizer from <a href="https://github.com/openai/CLIP/blob/main/clip/simple_tokenizer.py">https://github.com/openai/CLIP/blob/main/clip/simple_tokenizer.py</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model">Model<a class="anchor-link" href="#Model"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="vitb32_config" class="doc_header"><code>vitb32_config</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L40" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>vitb32_config</code>(<strong><code>input_res</code></strong>, <strong><code>context_length</code></strong>, <strong><code>vocab_size</code></strong>)</p>
</blockquote>
<p>ViT-B/32 configuration, uses 32x32 patches</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="vitl14_config" class="doc_header"><code>vitl14_config</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L54" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>vitl14_config</code>(<strong><code>input_res</code></strong>, <strong><code>context_length</code></strong>, <strong><code>vocab_size</code></strong>)</p>
</blockquote>
<p>ViT-L/14 configuration, uses 14x14 patches</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Bottleneck" class="doc_header"><code>class</code> <code>Bottleneck</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L72" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Bottleneck</code>(<strong><code>inplanes</code></strong>, <strong><code>planes</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AttentionPool2d" class="doc_header"><code>class</code> <code>AttentionPool2d</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L118" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AttentionPool2d</code>(<strong><code>spacial_dim</code></strong>:<code>int</code>, <strong><code>embed_dim</code></strong>:<code>int</code>, <strong><code>num_heads</code></strong>:<code>int</code>, <strong><code>output_dim</code></strong>:<code>int</code>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ModifiedResNet" class="doc_header"><code>class</code> <code>ModifiedResNet</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L155" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ModifiedResNet</code>(<strong><code>layers</code></strong>, <strong><code>output_dim</code></strong>, <strong><code>heads</code></strong>, <strong><code>input_resolution</code></strong>=<em><code>224</code></em>, <strong><code>width</code></strong>=<em><code>64</code></em>) :: <code>Module</code></p>
</blockquote>
<p>A ResNet class that is similar to torchvision's but contains the following changes:</p>
<ul>
<li>There are now 3 "stem" convolutions as opposed to 1, with an average pool instead of a max pool.</li>
<li>Performs anti-aliasing strided convolutions, where an avgpool is prepended to convolutions with stride &gt; 1</li>
<li>The final pooling layer is a QKV attention instead of an average pool</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LayerNorm" class="doc_header"><code>class</code> <code>LayerNorm</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L215" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LayerNorm</code>(<strong><code>normalized_shape</code></strong>:<code>Union</code>[<code>int</code>, <code>List</code>[<code>int</code>], <code>Size</code>], <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-05</code></em>, <strong><code>elementwise_affine</code></strong>:<code>bool</code>=<em><code>True</code></em>) :: <a href="/self_supervised/21 - clip-moco.html#LayerNorm"><code>LayerNorm</code></a></p>
</blockquote>
<p>Subclass torch's LayerNorm to handle fp16.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="QuickGELU" class="doc_header"><code>class</code> <code>QuickGELU</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L224" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>QuickGELU</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResidualAttentionBlock" class="doc_header"><code>class</code> <code>ResidualAttentionBlock</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L229" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResidualAttentionBlock</code>(<strong><code>d_model</code></strong>:<code>int</code>, <strong><code>n_head</code></strong>:<code>int</code>, <strong><code>attn_mask</code></strong>:<code>Tensor</code>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Transformer" class="doc_header"><code>class</code> <code>Transformer</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L253" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Transformer</code>(<strong><code>width</code></strong>:<code>int</code>, <strong><code>layers</code></strong>:<code>int</code>, <strong><code>heads</code></strong>:<code>int</code>, <strong><code>attn_mask</code></strong>:<code>Tensor</code>=<em><code>None</code></em>, <strong><code>checkpoint</code></strong>=<em><code>False</code></em>, <strong><code>checkpoint_nchunks</code></strong>=<em><code>2</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VisualTransformer" class="doc_header"><code>class</code> <code>VisualTransformer</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L267" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VisualTransformer</code>(<strong><code>input_resolution</code></strong>:<code>int</code>, <strong><code>patch_size</code></strong>:<code>int</code>, <strong><code>width</code></strong>:<code>int</code>, <strong><code>layers</code></strong>:<code>int</code>, <strong><code>heads</code></strong>:<code>int</code>, <strong><code>output_dim</code></strong>:<code>int</code>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CLIPMOCO" class="doc_header"><code>class</code> <code>CLIPMOCO</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L304" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CLIPMOCO</code>(<strong><code>embed_dim</code></strong>:<code>int</code>, <strong><code>image_resolution</code></strong>:<code>int</code>, <strong><code>vision_layers</code></strong>:<code>Union</code>[<code>Tuple</code>[<code>int</code>, <code>int</code>, <code>int</code>, <code>int</code>], <code>int</code>], <strong><code>vision_width</code></strong>:<code>int</code>, <strong><code>vision_patch_size</code></strong>:<code>int</code>, <strong><code>context_length</code></strong>:<code>int</code>, <strong><code>vocab_size</code></strong>:<code>int</code>, <strong><code>transformer_width</code></strong>:<code>int</code>, <strong><code>transformer_heads</code></strong>:<code>int</code>, <strong><code>transformer_layers</code></strong>:<code>int</code>, <strong><code>K</code></strong>=<em><code>4096</code></em>, <strong><code>m</code></strong>=<em><code>0.999</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Metric">Metric<a class="anchor-link" href="#Metric"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A useful proxy metric for tracking training performance and convergence.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="RetrievalAtK" class="doc_header"><code>class</code> <code>RetrievalAtK</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L496" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>RetrievalAtK</code>(<strong><code>k</code></strong>=<em><code>20</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>AccumMetric</code></p>
</blockquote>
<p>Stores predictions and targets on CPU in accumulate to perform final calculations with <code>func</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CLIP-MoCo-Callback">CLIP-MoCo Callback<a class="anchor-link" href="#CLIP-MoCo-Callback"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CLIPMOCOTrainer" class="doc_header"><code>class</code> <code>CLIPMOCOTrainer</code><a href="https://github.com/keremturgutlu/self_supervised/tree/main/self_supervised/multimodal/clip_moco.py#L525" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CLIPMOCOTrainer</code>(<strong><code>after_create</code></strong>=<em><code>None</code></em>, <strong><code>before_fit</code></strong>=<em><code>None</code></em>, <strong><code>before_epoch</code></strong>=<em><code>None</code></em>, <strong><code>before_train</code></strong>=<em><code>None</code></em>, <strong><code>before_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_pred</code></strong>=<em><code>None</code></em>, <strong><code>after_loss</code></strong>=<em><code>None</code></em>, <strong><code>before_backward</code></strong>=<em><code>None</code></em>, <strong><code>before_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_step</code></strong>=<em><code>None</code></em>, <strong><code>after_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_train</code></strong>=<em><code>None</code></em>, <strong><code>after_train</code></strong>=<em><code>None</code></em>, <strong><code>before_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_fit</code></strong>=<em><code>None</code></em>, <strong><code>after_fit</code></strong>=<em><code>None</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>MoCo Loss for CLIP. Can be used with or without DistributedDataParallel</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example-Usage">Example Usage<a class="anchor-link" href="#Example-Usage"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num2txt</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;3&#39;</span><span class="p">:</span> <span class="s1">&#39;three&#39;</span><span class="p">,</span> <span class="s1">&#39;7&#39;</span><span class="p">:</span> <span class="s1">&#39;seven&#39;</span><span class="p">}</span>
<span class="k">def</span> <span class="nf">num_to_txt</span><span class="p">(</span><span class="n">o</span><span class="p">):</span> <span class="k">return</span> <span class="n">num2txt</span><span class="p">[</span><span class="n">o</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">dummy_targ</span><span class="p">(</span><span class="n">o</span><span class="p">):</span> <span class="k">return</span> <span class="mi">0</span> <span class="c1"># loss func is not called without it</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_TINY</span><span class="p">)</span>
<span class="n">items</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">clip_tokenizer</span> <span class="o">=</span> <span class="n">ClipTokenizer</span><span class="p">()</span>
<span class="n">tds</span> <span class="o">=</span> <span class="n">Datasets</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="p">[</span><span class="n">PILImage</span><span class="o">.</span><span class="n">create</span><span class="p">,</span> <span class="p">[</span><span class="n">parent_label</span><span class="p">,</span> <span class="n">num_to_txt</span><span class="p">],</span> <span class="n">dummy_targ</span><span class="p">],</span> <span class="n">n_inp</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">GrandparentSplitter</span><span class="p">()(</span><span class="n">items</span><span class="p">))</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">tds</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">after_item</span><span class="o">=</span><span class="p">[</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span> <span class="n">clip_tokenizer</span><span class="p">,</span> <span class="n">ToTensor</span><span class="p">()],</span> <span class="n">after_batch</span><span class="o">=</span><span class="p">[</span><span class="n">IntToFloatTensor</span><span class="p">()],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vitb32_config_dict</span> <span class="o">=</span> <span class="n">vitb32_config</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="n">clip_tokenizer</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="n">clip_tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">clip_model</span> <span class="o">=</span> <span class="n">CLIPMOCO</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span><span class="n">m</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="o">**</span><span class="n">vitb32_config_dict</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">checkpoint_nchunks</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">clip_model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">noop</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">CLIPMOCOTrainer</span><span class="p">(),</span> <span class="n">ShortEpochCallback</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)],</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">RetrievalAtK</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> 
                           <span class="n">RetrievalAtK</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> 
                           <span class="n">RetrievalAtK</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">),</span>
                           <span class="n">RetrievalAtK</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

