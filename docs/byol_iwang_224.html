---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/examples/byol_iwang_224.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/examples/byol_iwang_224.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning:-https://arxiv.org/pdf/2006.07733.pdf"><strong>Bootstrap Your Own Latent A New Approach to Self-Supervised Learning:</strong> <a href="https://arxiv.org/pdf/2006.07733.pdf">https://arxiv.org/pdf/2006.07733.pdf</a><a class="anchor-link" href="#Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning:-https://arxiv.org/pdf/2006.07733.pdf"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">fastai</span><span class="o">,</span> <span class="nn">fastcore</span><span class="o">,</span> <span class="nn">torch</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fastai</span><span class="o">.</span><span class="n">__version__</span> <span class="p">,</span> <span class="n">fastcore</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;2.0.8&#39;, &#39;1.0.1&#39;, &#39;1.6.0+cu101&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sizes">Sizes<a class="anchor-link" href="#Sizes"> </a></h3><p>Resize -&gt; RandomCrop</p>
<p>320 -&gt; 256 | 224 -&gt; 192 | 160 -&gt; 128 or 256 -&gt; 224</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">resize</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">size</span> <span class="o">=</span> <span class="mi">224</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Implementation-Details-(Section-3.2-from-the-paper)">1. Implementation Details (Section 3.2 from the paper)<a class="anchor-link" href="#1.-Implementation-Details-(Section-3.2-from-the-paper)"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.1-Image-Augmentations">1.1 Image Augmentations<a class="anchor-link" href="#1.1-Image-Augmentations"> </a></h3><p>Same as SimCLR with optional grayscale</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">kornia</span>
<span class="k">def</span> <span class="nf">get_aug_pipe</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">stats</span><span class="o">=</span><span class="n">imagenet_stats</span><span class="p">,</span> <span class="n">s</span><span class="o">=.</span><span class="mi">6</span><span class="p">):</span>
    <span class="s2">&quot;SimCLR augmentations&quot;</span>
    <span class="n">rrc</span> <span class="o">=</span> <span class="n">kornia</span><span class="o">.</span><span class="n">augmentation</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="o">/</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">rhf</span> <span class="o">=</span> <span class="n">kornia</span><span class="o">.</span><span class="n">augmentation</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">()</span>
    <span class="n">rcj</span> <span class="o">=</span> <span class="n">kornia</span><span class="o">.</span><span class="n">augmentation</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="mf">0.8</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="mf">0.8</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
    <span class="n">rgs</span> <span class="o">=</span> <span class="n">kornia</span><span class="o">.</span><span class="n">augmentation</span><span class="o">.</span><span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    
    <span class="n">tfms</span> <span class="o">=</span> <span class="p">[</span><span class="n">rrc</span><span class="p">,</span> <span class="n">rhf</span><span class="p">,</span> <span class="n">rcj</span><span class="p">,</span> <span class="n">rgs</span><span class="p">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="n">from_stats</span><span class="p">(</span><span class="o">*</span><span class="n">stats</span><span class="p">)]</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">tfms</span><span class="p">)</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">split_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">pipe</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.2-Architecture">1.2 Architecture<a class="anchor-link" href="#1.2-Architecture"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_encoder</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">n_in</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">concat_pool</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="s2">&quot;Create encoder from a given arch backbone&quot;</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">create_body</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">n_in</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">cut</span><span class="p">)</span>
    <span class="n">pool</span> <span class="o">=</span> <span class="n">AdaptiveConcatPool2d</span><span class="p">()</span> <span class="k">if</span> <span class="n">concat_pool</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">encoder</span><span class="p">,</span> <span class="n">pool</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">&quot;MLP module as described in paper&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">projection_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">projection_size</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">BYOLModel</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">&quot;Compute predictions of v1 and v2&quot;</span> 
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">encoder</span><span class="p">,</span><span class="n">projector</span><span class="p">,</span><span class="n">predictor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">,</span><span class="n">projector</span><span class="p">,</span><span class="n">predictor</span>    

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">v1</span><span class="p">,</span><span class="n">v2</span><span class="p">):</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">v1</span><span class="p">)))</span>
        <span class="n">q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">v2</span><span class="p">)))</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">q1</span><span class="p">,</span><span class="n">q2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_byol_model</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="n">resnet50</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">projection_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">concat_pool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">create_encoder</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="n">pretrained</span><span class="p">,</span> <span class="n">concat_pool</span><span class="o">=</span><span class="n">concat_pool</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> 
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">))</span>
        <span class="n">representation</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">projector</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">representation</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">projection_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span>     
    <span class="n">predictor</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">projection_size</span><span class="p">,</span> <span class="n">projection_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="n">apply_init</span><span class="p">(</span><span class="n">projector</span><span class="p">)</span>
    <span class="n">apply_init</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">BYOLModel</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">projector</span><span class="p">,</span> <span class="n">predictor</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.3-BYOLCallback">1.3 BYOLCallback<a class="anchor-link" href="#1.3-BYOLCallback"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">_mse_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">symmetric_mse_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="o">*</span><span class="n">yb</span><span class="p">):</span>
    <span class="p">(</span><span class="n">q1</span><span class="p">,</span><span class="n">q2</span><span class="p">),</span><span class="n">z1</span><span class="p">,</span><span class="n">z2</span> <span class="o">=</span> <span class="n">pred</span><span class="p">,</span><span class="o">*</span><span class="n">yb</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">_mse_loss</span><span class="p">(</span><span class="n">q1</span><span class="p">,</span><span class="n">z2</span><span class="p">)</span> <span class="o">+</span> <span class="n">_mse_loss</span><span class="p">(</span><span class="n">q2</span><span class="p">,</span><span class="n">z1</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">symmetric_mse_loss</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># perfect</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">symmetric_mse_loss</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">)</span> <span class="c1"># random</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Useful Discussions and Supportive Material:</p>
<ul>
<li><a href="https://www.reddit.com/r/MachineLearning/comments/hju274/d_byol_bootstrap_your_own_latent_cheating/fwohtky/">https://www.reddit.com/r/MachineLearning/comments/hju274/d_byol_bootstrap_your_own_latent_cheating/fwohtky/</a></li>
<li><a href="https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</a></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>

<span class="k">class</span> <span class="nc">BYOLCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="s2">&quot;Implementation of https://arxiv.org/pdf/2006.07733.pdf&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="o">**</span><span class="n">aug_kwargs</span><span class="p">):</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug</span> <span class="o">=</span> <span class="n">T</span><span class="p">,</span> <span class="n">debug</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aug1</span> <span class="o">=</span> <span class="n">get_aug_pipe</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="o">**</span><span class="n">aug_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aug2</span> <span class="o">=</span> <span class="n">get_aug_pipe</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="o">**</span><span class="n">aug_kwargs</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">before_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Create target model&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">T_sched</span> <span class="o">=</span> <span class="n">SchedCos</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># used in paper</span>
        <span class="c1"># self.T_sched = SchedNo(self.T, 1) # used in open source implementation</span>
  
        
    <span class="k">def</span> <span class="nf">before_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Generate 2 views of the same image and calculate target projections for these views&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;self.x[0]: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">v1</span><span class="p">,</span><span class="n">v2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aug1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">aug2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">xb</span> <span class="o">=</span> <span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="n">v2</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;v1[0]: </span><span class="si">{</span><span class="n">v1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">v2[0]: </span><span class="si">{</span><span class="n">v2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">show_one</span><span class="p">()</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">xb</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">v1</span><span class="p">))</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">v2</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">yb</span> <span class="o">=</span> <span class="p">(</span><span class="n">z1</span><span class="p">,</span><span class="n">z2</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">after_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Update target model and T&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_sched</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pct_train</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">param_k</span><span class="p">,</span> <span class="n">param_q</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
                <span class="n">param_k</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param_k</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">param_q</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
          

    <span class="k">def</span> <span class="nf">show_one</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">b1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aug1</span><span class="o">.</span><span class="n">normalize</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">to_detach</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">xb</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">b2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aug1</span><span class="o">.</span><span class="n">normalize</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">to_detach</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">xb</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b1</span><span class="p">))</span>
        <span class="n">show_images</span><span class="p">([</span><span class="n">b1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">b2</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">after_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>      
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">show_one</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">after_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>   
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">show_one</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Pretext-Training">2. Pretext Training<a class="anchor-link" href="#2.-Pretext-Training"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sqrmom</span><span class="o">=</span><span class="mf">0.99</span>
<span class="n">mom</span><span class="o">=</span><span class="mf">0.95</span>
<span class="n">beta</span><span class="o">=</span><span class="mf">0.</span>
<span class="n">eps</span><span class="o">=</span><span class="mf">1e-4</span>
<span class="n">opt_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">ranger</span><span class="p">,</span> <span class="n">mom</span><span class="o">=</span><span class="n">mom</span><span class="p">,</span> <span class="n">sqr_mom</span><span class="o">=</span><span class="n">sqrmom</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span><span class="o">=</span><span class="mi">128</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_dls</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">URLs</span><span class="o">.</span><span class="n">IMAGEWANG_160</span> <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;=</span> <span class="mi">160</span> <span class="k">else</span> <span class="n">URLs</span><span class="o">.</span><span class="n">IMAGEWANG</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    
    <span class="n">files</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
    <span class="n">tfms</span> <span class="o">=</span> <span class="p">[[</span><span class="n">PILImage</span><span class="o">.</span><span class="n">create</span><span class="p">,</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)],</span> 
            <span class="p">[</span><span class="n">parent_label</span><span class="p">,</span> <span class="n">Categorize</span><span class="p">()]]</span>
    
    <span class="n">dsets</span> <span class="o">=</span> <span class="n">Datasets</span><span class="p">(</span><span class="n">files</span><span class="p">,</span> <span class="n">tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">files</span><span class="p">))</span>
    
    <span class="n">batch_tfms</span> <span class="o">=</span> <span class="p">[</span><span class="n">IntToFloatTensor</span><span class="p">]</span>
    <span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">after_batch</span><span class="o">=</span><span class="n">batch_tfms</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dls</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">get_dls</span><span class="p">(</span><span class="n">resize</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_byol_model</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="n">xresnet34</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">symmetric_mse_loss</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">opt_func</span><span class="p">,</span>
                <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">BYOLCallback</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">TerminateOnNaNCallback</span><span class="p">()])</span>
<span class="c1"># learn.to_fp16();</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.017378008365631102, lr_steep=0.0008317637839354575)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span>
<span class="n">wd</span><span class="o">=</span><span class="mf">1e-2</span>
<span class="n">epochs</span><span class="o">=</span><span class="mi">200</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="n">pct_start</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.510757</td>
      <td>1.441171</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.169911</td>
      <td>1.107077</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.951738</td>
      <td>0.964509</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.832323</td>
      <td>0.835626</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.753680</td>
      <td>0.780289</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.714660</td>
      <td>0.702578</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.680086</td>
      <td>0.713753</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.651360</td>
      <td>0.684436</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.645680</td>
      <td>0.684706</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.633862</td>
      <td>0.671666</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.636757</td>
      <td>0.645753</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.602091</td>
      <td>0.662510</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.590807</td>
      <td>0.651916</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.584243</td>
      <td>0.639185</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.567478</td>
      <td>0.624629</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.567509</td>
      <td>0.713023</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.563198</td>
      <td>0.707810</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.559214</td>
      <td>0.593231</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.549363</td>
      <td>0.654259</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.543426</td>
      <td>0.668211</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.530272</td>
      <td>0.573803</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.515820</td>
      <td>0.634096</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.529596</td>
      <td>0.648341</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.512476</td>
      <td>0.641050</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.493914</td>
      <td>0.630478</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.482132</td>
      <td>0.621057</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.480202</td>
      <td>0.604333</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.484736</td>
      <td>0.595756</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.471681</td>
      <td>0.596620</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.457629</td>
      <td>0.575932</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.470514</td>
      <td>0.668943</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>31</td>
      <td>0.466108</td>
      <td>0.575433</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>32</td>
      <td>0.458568</td>
      <td>0.619704</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>33</td>
      <td>0.433868</td>
      <td>0.662057</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.431475</td>
      <td>0.637153</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>35</td>
      <td>0.417072</td>
      <td>0.617716</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>36</td>
      <td>0.429638</td>
      <td>0.603475</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.414385</td>
      <td>0.618626</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>38</td>
      <td>0.398022</td>
      <td>0.648765</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.410112</td>
      <td>0.586348</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>40</td>
      <td>0.435796</td>
      <td>0.603527</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>41</td>
      <td>0.384723</td>
      <td>0.576219</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>42</td>
      <td>0.386799</td>
      <td>0.592261</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>43</td>
      <td>0.391173</td>
      <td>0.643356</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>44</td>
      <td>0.405267</td>
      <td>0.588073</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>45</td>
      <td>0.393818</td>
      <td>0.629431</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>46</td>
      <td>0.395968</td>
      <td>0.616174</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>47</td>
      <td>0.373980</td>
      <td>0.518790</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>48</td>
      <td>0.371791</td>
      <td>0.606675</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>49</td>
      <td>0.371367</td>
      <td>0.562422</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>50</td>
      <td>0.369227</td>
      <td>0.570649</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>51</td>
      <td>0.377560</td>
      <td>0.533208</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>52</td>
      <td>0.389959</td>
      <td>0.595424</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>53</td>
      <td>0.370385</td>
      <td>0.609593</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>54</td>
      <td>0.371633</td>
      <td>0.579477</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>55</td>
      <td>0.374386</td>
      <td>0.672765</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>56</td>
      <td>0.351740</td>
      <td>0.614809</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>57</td>
      <td>0.373552</td>
      <td>0.613566</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>58</td>
      <td>0.372335</td>
      <td>0.596740</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>59</td>
      <td>0.355892</td>
      <td>0.567010</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>60</td>
      <td>0.361140</td>
      <td>0.569466</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>61</td>
      <td>0.377742</td>
      <td>0.608946</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>62</td>
      <td>0.354400</td>
      <td>0.633960</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>63</td>
      <td>0.350570</td>
      <td>0.550820</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>64</td>
      <td>0.361100</td>
      <td>0.535284</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>65</td>
      <td>0.347026</td>
      <td>0.620467</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>66</td>
      <td>0.364227</td>
      <td>0.545692</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>67</td>
      <td>0.367467</td>
      <td>0.537868</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>68</td>
      <td>0.350294</td>
      <td>0.632469</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>69</td>
      <td>0.357263</td>
      <td>0.525969</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>70</td>
      <td>0.355860</td>
      <td>0.533970</td>
      <td>04:00</td>
    </tr>
    <tr>
      <td>71</td>
      <td>0.343607</td>
      <td>0.590966</td>
      <td>04:00</td>
    </tr>
    <tr>
      <td>72</td>
      <td>0.338395</td>
      <td>0.494025</td>
      <td>04:00</td>
    </tr>
    <tr>
      <td>73</td>
      <td>0.356462</td>
      <td>0.569043</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>74</td>
      <td>0.352770</td>
      <td>0.515759</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>75</td>
      <td>0.366795</td>
      <td>0.558499</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>76</td>
      <td>0.346711</td>
      <td>0.526549</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>77</td>
      <td>0.331778</td>
      <td>0.515826</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>78</td>
      <td>0.343425</td>
      <td>0.596540</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>79</td>
      <td>0.344705</td>
      <td>0.566005</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>80</td>
      <td>0.348332</td>
      <td>0.605634</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>81</td>
      <td>0.336831</td>
      <td>0.609262</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>82</td>
      <td>0.341431</td>
      <td>0.615540</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>83</td>
      <td>0.333731</td>
      <td>0.599741</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>84</td>
      <td>0.337825</td>
      <td>0.714763</td>
      <td>03:59</td>
    </tr>
    <tr>
      <td>85</td>
      <td>0.333903</td>
      <td>0.575222</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>86</td>
      <td>0.338704</td>
      <td>0.492768</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>87</td>
      <td>0.316828</td>
      <td>0.555608</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>88</td>
      <td>0.331051</td>
      <td>0.552337</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>89</td>
      <td>0.354539</td>
      <td>0.526341</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>90</td>
      <td>0.338537</td>
      <td>0.599413</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>91</td>
      <td>0.332460</td>
      <td>0.672619</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>92</td>
      <td>0.322493</td>
      <td>0.545617</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>93</td>
      <td>0.336264</td>
      <td>0.602922</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>94</td>
      <td>0.327776</td>
      <td>0.601617</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>95</td>
      <td>0.319898</td>
      <td>0.505920</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>96</td>
      <td>0.346555</td>
      <td>0.613650</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>97</td>
      <td>0.341267</td>
      <td>0.602153</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>98</td>
      <td>0.329472</td>
      <td>0.563208</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>99</td>
      <td>0.321007</td>
      <td>0.504871</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>100</td>
      <td>0.317550</td>
      <td>0.604534</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>101</td>
      <td>0.320216</td>
      <td>0.587887</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>102</td>
      <td>0.336398</td>
      <td>0.536860</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>103</td>
      <td>0.334062</td>
      <td>0.558356</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>104</td>
      <td>0.333434</td>
      <td>0.599490</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>105</td>
      <td>0.313463</td>
      <td>0.552483</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>106</td>
      <td>0.309765</td>
      <td>0.731097</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>107</td>
      <td>0.325262</td>
      <td>0.585587</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>108</td>
      <td>0.331552</td>
      <td>0.650310</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>109</td>
      <td>0.352506</td>
      <td>0.534563</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>110</td>
      <td>0.314924</td>
      <td>0.515463</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>111</td>
      <td>0.341231</td>
      <td>0.550203</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>112</td>
      <td>0.332862</td>
      <td>0.541130</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>113</td>
      <td>0.328369</td>
      <td>0.552456</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>114</td>
      <td>0.333167</td>
      <td>0.561218</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>115</td>
      <td>0.320298</td>
      <td>0.532742</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>116</td>
      <td>0.308208</td>
      <td>0.535793</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>117</td>
      <td>0.322896</td>
      <td>0.555967</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>118</td>
      <td>0.328948</td>
      <td>0.614606</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>119</td>
      <td>0.311387</td>
      <td>0.511014</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>120</td>
      <td>0.328214</td>
      <td>0.564817</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>121</td>
      <td>0.318232</td>
      <td>0.472088</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>122</td>
      <td>0.333587</td>
      <td>0.574538</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>123</td>
      <td>0.296986</td>
      <td>0.590455</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>124</td>
      <td>0.305950</td>
      <td>0.572258</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>125</td>
      <td>0.306559</td>
      <td>0.619074</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>126</td>
      <td>0.305197</td>
      <td>0.652843</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>127</td>
      <td>0.313741</td>
      <td>0.616515</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>128</td>
      <td>0.325584</td>
      <td>0.575967</td>
      <td>03:58</td>
    </tr>
    <tr>
      <td>129</td>
      <td>0.315431</td>
      <td>0.593895</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>130</td>
      <td>0.303507</td>
      <td>0.598538</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>131</td>
      <td>0.301052</td>
      <td>0.523514</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>132</td>
      <td>0.306886</td>
      <td>0.470229</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>133</td>
      <td>0.311341</td>
      <td>0.592421</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>134</td>
      <td>0.306590</td>
      <td>0.638961</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>135</td>
      <td>0.326948</td>
      <td>0.650875</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>136</td>
      <td>0.310750</td>
      <td>0.624421</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>137</td>
      <td>0.313424</td>
      <td>0.623253</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>138</td>
      <td>0.320651</td>
      <td>0.600835</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>139</td>
      <td>0.303238</td>
      <td>0.536873</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>140</td>
      <td>0.306607</td>
      <td>0.553378</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>141</td>
      <td>0.309926</td>
      <td>0.470754</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>142</td>
      <td>0.303768</td>
      <td>0.613379</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>143</td>
      <td>0.303442</td>
      <td>0.635326</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>144</td>
      <td>0.308513</td>
      <td>0.535352</td>
      <td>03:57</td>
    </tr>
    <tr>
      <td>145</td>
      <td>0.324150</td>
      <td>0.588213</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>146</td>
      <td>0.296180</td>
      <td>0.529592</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>147</td>
      <td>0.306978</td>
      <td>0.540337</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>148</td>
      <td>0.312523</td>
      <td>0.506931</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>149</td>
      <td>0.317547</td>
      <td>0.587346</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>150</td>
      <td>0.304757</td>
      <td>0.539795</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>151</td>
      <td>0.301003</td>
      <td>0.625814</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>152</td>
      <td>0.322560</td>
      <td>0.529840</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>153</td>
      <td>0.290061</td>
      <td>0.443123</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>154</td>
      <td>0.306191</td>
      <td>0.566525</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>155</td>
      <td>0.311446</td>
      <td>0.544719</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>156</td>
      <td>0.286784</td>
      <td>0.577996</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>157</td>
      <td>0.306480</td>
      <td>0.535883</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>158</td>
      <td>0.308643</td>
      <td>0.582453</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>159</td>
      <td>0.291006</td>
      <td>0.534699</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>160</td>
      <td>0.296693</td>
      <td>0.597577</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>161</td>
      <td>0.296524</td>
      <td>0.592290</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>162</td>
      <td>0.282526</td>
      <td>0.522779</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>163</td>
      <td>0.311050</td>
      <td>0.612963</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>164</td>
      <td>0.300357</td>
      <td>0.501484</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>165</td>
      <td>0.294963</td>
      <td>0.626009</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>166</td>
      <td>0.285499</td>
      <td>0.669717</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>167</td>
      <td>0.286229</td>
      <td>0.702356</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>168</td>
      <td>0.281513</td>
      <td>0.524852</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>169</td>
      <td>0.306334</td>
      <td>0.659596</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>170</td>
      <td>0.309618</td>
      <td>0.566389</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>171</td>
      <td>0.294460</td>
      <td>0.614964</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>172</td>
      <td>0.283630</td>
      <td>0.627757</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>173</td>
      <td>0.298762</td>
      <td>0.639979</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>174</td>
      <td>0.293329</td>
      <td>0.483771</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>175</td>
      <td>0.301671</td>
      <td>0.599483</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>176</td>
      <td>0.308904</td>
      <td>0.671758</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>177</td>
      <td>0.293808</td>
      <td>0.468399</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>178</td>
      <td>0.320875</td>
      <td>0.526614</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>179</td>
      <td>0.286953</td>
      <td>0.621383</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>180</td>
      <td>0.300920</td>
      <td>0.550090</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>181</td>
      <td>0.308400</td>
      <td>0.608852</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>182</td>
      <td>0.313575</td>
      <td>0.445545</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>183</td>
      <td>0.295628</td>
      <td>0.523261</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>184</td>
      <td>0.294733</td>
      <td>0.482230</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>185</td>
      <td>0.309171</td>
      <td>0.531699</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>186</td>
      <td>0.303061</td>
      <td>0.572620</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>187</td>
      <td>0.299710</td>
      <td>0.523177</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>188</td>
      <td>0.300880</td>
      <td>0.576149</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>189</td>
      <td>0.303390</td>
      <td>0.543893</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>190</td>
      <td>0.294037</td>
      <td>0.637041</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>191</td>
      <td>0.316425</td>
      <td>0.553113</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>192</td>
      <td>0.289703</td>
      <td>0.600885</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>193</td>
      <td>0.286491</td>
      <td>0.587131</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>194</td>
      <td>0.297807</td>
      <td>0.576624</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>195</td>
      <td>0.303526</td>
      <td>0.542772</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>196</td>
      <td>0.307309</td>
      <td>0.635088</td>
      <td>03:54</td>
    </tr>
    <tr>
      <td>197</td>
      <td>0.317049</td>
      <td>0.534224</td>
      <td>03:55</td>
    </tr>
    <tr>
      <td>198</td>
      <td>0.294045</td>
      <td>0.544807</td>
      <td>03:56</td>
    </tr>
    <tr>
      <td>199</td>
      <td>0.300524</td>
      <td>0.545782</td>
      <td>03:55</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">save_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;byol_iwang_sz</span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s1">_epc</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_name</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">learn</span><span class="o">.</span><span class="n">path</span><span class="o">/</span><span class="n">learn</span><span class="o">.</span><span class="n">model_dir</span><span class="o">/</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">save_name</span><span class="si">}</span><span class="s1">_encoder.pth&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_name</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Downstream-Task---Image-Classification">3. Downstream Task - Image Classification<a class="anchor-link" href="#3.-Downstream-Task---Image-Classification"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_dls</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">URLs</span><span class="o">.</span><span class="n">IMAGEWANG_160</span> <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;=</span> <span class="mi">160</span> <span class="k">else</span> <span class="n">URLs</span><span class="o">.</span><span class="n">IMAGEWANG</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">files</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">folders</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">])</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="n">GrandparentSplitter</span><span class="p">(</span><span class="n">valid_name</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">)(</span><span class="n">files</span><span class="p">)</span>
    
    <span class="n">item_aug</span> <span class="o">=</span> <span class="p">[</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.35</span><span class="p">),</span> <span class="n">FlipItem</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)]</span>
    <span class="n">tfms</span> <span class="o">=</span> <span class="p">[[</span><span class="n">PILImage</span><span class="o">.</span><span class="n">create</span><span class="p">,</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="o">*</span><span class="n">item_aug</span><span class="p">],</span> 
            <span class="p">[</span><span class="n">parent_label</span><span class="p">,</span> <span class="n">Categorize</span><span class="p">()]]</span>
    
    <span class="n">dsets</span> <span class="o">=</span> <span class="n">Datasets</span><span class="p">(</span><span class="n">files</span><span class="p">,</span> <span class="n">tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">)</span>
    
    <span class="n">batch_tfms</span> <span class="o">=</span> <span class="p">[</span><span class="n">IntToFloatTensor</span><span class="p">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="n">from_stats</span><span class="p">(</span><span class="o">*</span><span class="n">imagenet_stats</span><span class="p">)]</span>
    <span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">after_batch</span><span class="o">=</span><span class="n">batch_tfms</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dls</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">do_train</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">runs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="n">lr</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">save_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">dls</span> <span class="o">=</span> <span class="n">get_dls</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">run</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">runs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Run: </span><span class="si">{</span><span class="n">run</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">xresnet34</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">opt_func</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span><span class="n">top_k_accuracy</span><span class="p">],</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">LabelSmoothingCrossEntropy</span><span class="p">(),</span>
                <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#         learn.to_fp16()</span>
        
        <span class="k">if</span> <span class="n">save_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">path</span><span class="o">/</span><span class="n">learn</span><span class="o">.</span><span class="n">model_dir</span><span class="o">/</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">save_name</span><span class="si">}</span><span class="s1">_encoder.pth&#39;</span><span class="p">)</span>
            <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model loaded...&quot;</span><span class="p">)</span>
            
        <span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ImageWang-Leaderboard">ImageWang Leaderboard<a class="anchor-link" href="#ImageWang-Leaderboard"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>sz-224</strong></p>
<p><strong>Contrastive Learning</strong></p>
<ul>
<li>5 epochs:  67.70%</li>
<li>20 epochs: 70.03%</li>
<li>80 epochs: 70.71%</li>
<li>200 epochs: 71.78%</li>
</ul>
<p><strong>BYOL</strong></p>
<ul>
<li>5 epochs: </li>
<li>20 epochs:</li>
<li>80 epochs:</li>
<li>200 epochs:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="5-epochs">5 epochs<a class="anchor-link" href="#5-epochs"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># link: https://github.com/KeremTurgutlu/self_supervised/blob/252269827da41b41091cf0db533b65c0d1312f85/nbs/byol_iwang_192.ipynb</span>
<span class="c1"># save_name = &#39;byol_iwang_sz192_epc230&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">wd</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">runs</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do_train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">runs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">save_name</span><span class="o">=</span><span class="n">save_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 0
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.957977</td>
      <td>3.159999</td>
      <td>0.144566</td>
      <td>0.597608</td>
      <td>01:28</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.522225</td>
      <td>2.735217</td>
      <td>0.247900</td>
      <td>0.774243</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.316602</td>
      <td>11.871535</td>
      <td>0.034105</td>
      <td>0.463731</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.214706</td>
      <td>2.299502</td>
      <td>0.346908</td>
      <td>0.827437</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.094679</td>
      <td>1.983208</td>
      <td>0.462459</td>
      <td>0.876304</td>
      <td>01:27</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 1
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.978778</td>
      <td>3.957852</td>
      <td>0.049122</td>
      <td>0.437516</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.520571</td>
      <td>2.410347</td>
      <td>0.288369</td>
      <td>0.815220</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.303886</td>
      <td>2.450577</td>
      <td>0.299313</td>
      <td>0.794095</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.202353</td>
      <td>2.209358</td>
      <td>0.382795</td>
      <td>0.869687</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.085302</td>
      <td>1.905505</td>
      <td>0.488419</td>
      <td>0.884449</td>
      <td>01:26</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 2
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.974360</td>
      <td>3.624461</td>
      <td>0.077628</td>
      <td>0.565284</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.523408</td>
      <td>2.578053</td>
      <td>0.235429</td>
      <td>0.722321</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.316594</td>
      <td>3.448142</td>
      <td>0.070247</td>
      <td>0.456859</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.200443</td>
      <td>2.164834</td>
      <td>0.397811</td>
      <td>0.836854</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.082367</td>
      <td>1.924870</td>
      <td>0.479511</td>
      <td>0.890048</td>
      <td>01:28</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 3
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.851579</td>
      <td>00:16</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-33-0db0bc94673e&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>do_train<span class="ansi-blue-fg">(</span>epochs<span class="ansi-blue-fg">,</span> runs<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">=</span>lr<span class="ansi-blue-fg">,</span> bs<span class="ansi-blue-fg">=</span>bs<span class="ansi-blue-fg">,</span> save_name<span class="ansi-blue-fg">=</span>save_name<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-30-b0b8b2fa2611&gt;</span> in <span class="ansi-cyan-fg">do_train</span><span class="ansi-blue-fg">(epochs, runs, lr, size, bs, save_name)</span>
<span class="ansi-green-intense-fg ansi-bold">     14</span> 
<span class="ansi-green-intense-fg ansi-bold">     15</span>         learn<span class="ansi-blue-fg">.</span>unfreeze<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 16</span><span class="ansi-red-fg">         </span>learn<span class="ansi-blue-fg">.</span>fit_flat_cos<span class="ansi-blue-fg">(</span>epochs<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">,</span> wd<span class="ansi-blue-fg">=</span>wd<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastcore/utils.py</span> in <span class="ansi-cyan-fg">_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span>         init_args<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>log<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    471</span>         setattr<span class="ansi-blue-fg">(</span>inst<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;init_args&#39;</span><span class="ansi-blue-fg">,</span> init_args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 472</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> inst <span class="ansi-green-fg">if</span> to_return <span class="ansi-green-fg">else</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span>     <span class="ansi-green-fg">return</span> _f
<span class="ansi-green-intense-fg ansi-bold">    474</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/callback/schedule.py</span> in <span class="ansi-cyan-fg">fit_flat_cos</span><span class="ansi-blue-fg">(self, n_epoch, lr, div_final, pct_start, wd, cbs, reset_opt)</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>     lr <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>array<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>h<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;lr&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> h <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>opt<span class="ansi-blue-fg">.</span>hypers<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    136</span>     scheds <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;lr&#39;</span><span class="ansi-blue-fg">:</span> combined_cos<span class="ansi-blue-fg">(</span>pct_start<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">/</span>div_final<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">--&gt; 137</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span>n_epoch<span class="ansi-blue-fg">,</span> cbs<span class="ansi-blue-fg">=</span>ParamScheduler<span class="ansi-blue-fg">(</span>scheds<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">+</span>L<span class="ansi-blue-fg">(</span>cbs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> reset_opt<span class="ansi-blue-fg">=</span>reset_opt<span class="ansi-blue-fg">,</span> wd<span class="ansi-blue-fg">=</span>wd<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    138</span> 
<span class="ansi-green-intense-fg ansi-bold">    139</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastcore/utils.py</span> in <span class="ansi-cyan-fg">_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span>         init_args<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>log<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    471</span>         setattr<span class="ansi-blue-fg">(</span>inst<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;init_args&#39;</span><span class="ansi-blue-fg">,</span> init_args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 472</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> inst <span class="ansi-green-fg">if</span> to_return <span class="ansi-green-fg">else</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span>     <span class="ansi-green-fg">return</span> _f
<span class="ansi-green-intense-fg ansi-bold">    474</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, n_epoch, lr, wd, cbs, reset_opt)</span>
<span class="ansi-green-intense-fg ansi-bold">    205</span>             self<span class="ansi-blue-fg">.</span>opt<span class="ansi-blue-fg">.</span>set_hypers<span class="ansi-blue-fg">(</span>lr<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>lr <span class="ansi-green-fg">if</span> lr <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">else</span> lr<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    206</span>             self<span class="ansi-blue-fg">.</span>n_epoch<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>loss <span class="ansi-blue-fg">=</span> n_epoch<span class="ansi-blue-fg">,</span>tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0.</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 207</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_do_fit<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;fit&#39;</span><span class="ansi-blue-fg">,</span> CancelFitException<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>_end_cleanup<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    208</span> 
<span class="ansi-green-intense-fg ansi-bold">    209</span>     <span class="ansi-green-fg">def</span> _end_cleanup<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>xb<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>yb<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>pred<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>loss <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_fit</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    195</span>         <span class="ansi-green-fg">for</span> epoch <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>n_epoch<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    196</span>             self<span class="ansi-blue-fg">.</span>epoch<span class="ansi-blue-fg">=</span>epoch
<span class="ansi-green-fg">--&gt; 197</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_do_epoch<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;epoch&#39;</span><span class="ansi-blue-fg">,</span> CancelEpochException<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    198</span> 
<span class="ansi-green-intense-fg ansi-bold">    199</span>     <span class="ansi-blue-fg">@</span>log_args<span class="ansi-blue-fg">(</span>but<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;cbs&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_epoch</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    189</span> 
<span class="ansi-green-intense-fg ansi-bold">    190</span>     <span class="ansi-green-fg">def</span> _do_epoch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 191</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_do_epoch_train<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    192</span>         self<span class="ansi-blue-fg">.</span>_do_epoch_validate<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    193</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_epoch_train</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    181</span>     <span class="ansi-green-fg">def</span> _do_epoch_train<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    182</span>         self<span class="ansi-blue-fg">.</span>dl <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dls<span class="ansi-blue-fg">.</span>train
<span class="ansi-green-fg">--&gt; 183</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>all_batches<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;train&#39;</span><span class="ansi-blue-fg">,</span> CancelTrainException<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    184</span> 
<span class="ansi-green-intense-fg ansi-bold">    185</span>     <span class="ansi-green-fg">def</span> _do_epoch_validate<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> ds_idx<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> dl<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">all_batches</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    159</span>     <span class="ansi-green-fg">def</span> all_batches<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    160</span>         self<span class="ansi-blue-fg">.</span>n_iter <span class="ansi-blue-fg">=</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 161</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">for</span> o <span class="ansi-green-fg">in</span> enumerate<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>one_batch<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>o<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span> 
<span class="ansi-green-intense-fg ansi-bold">    163</span>     <span class="ansi-green-fg">def</span> _do_one_batch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">one_batch</span><span class="ansi-blue-fg">(self, i, b)</span>
<span class="ansi-green-intense-fg ansi-bold">    177</span>         self<span class="ansi-blue-fg">.</span>iter <span class="ansi-blue-fg">=</span> i
<span class="ansi-green-intense-fg ansi-bold">    178</span>         self<span class="ansi-blue-fg">.</span>_split<span class="ansi-blue-fg">(</span>b<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 179</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_do_one_batch<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;batch&#39;</span><span class="ansi-blue-fg">,</span> CancelBatchException<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    180</span> 
<span class="ansi-green-intense-fg ansi-bold">    181</span>     <span class="ansi-green-fg">def</span> _do_epoch_train<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_one_batch</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span> 
<span class="ansi-green-intense-fg ansi-bold">    163</span>     <span class="ansi-green-fg">def</span> _do_one_batch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 164</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>pred <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>self<span class="ansi-blue-fg">.</span>xb<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    165</span>         self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_pred&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    166</span>         <span class="ansi-green-fg">if</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>yb<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>loss <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>loss_func<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>pred<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>self<span class="ansi-blue-fg">.</span>yb<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/layers.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, x)</span>
<span class="ansi-green-intense-fg ansi-bold">    576</span>         self<span class="ansi-blue-fg">.</span>act <span class="ansi-blue-fg">=</span> defaults<span class="ansi-blue-fg">.</span>activation<span class="ansi-blue-fg">(</span>inplace<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> act_cls <span class="ansi-green-fg">is</span> defaults<span class="ansi-blue-fg">.</span>activation <span class="ansi-green-fg">else</span> act_cls<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    577</span> 
<span class="ansi-green-fg">--&gt; 578</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>act<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>convpath<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> self<span class="ansi-blue-fg">.</span>idpath<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    579</span> 
<span class="ansi-green-intense-fg ansi-bold">    580</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    720</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    721</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 722</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    723</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    724</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span> 
<span class="ansi-green-intense-fg ansi-bold">    418</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 419</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_conv_forward<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>weight<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    420</span> 
<span class="ansi-green-intense-fg ansi-bold">    421</span> <span class="ansi-green-fg">class</span> Conv3d<span class="ansi-blue-fg">(</span>_ConvNd<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">_conv_forward</span><span class="ansi-blue-fg">(self, input, weight)</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span>                             _pair(0), self.dilation, self.groups)
<span class="ansi-green-intense-fg ansi-bold">    415</span>         return F.conv2d(input, weight, self.bias, self.stride,
<span class="ansi-green-fg">--&gt; 416</span><span class="ansi-red-fg">                         self.padding, self.dilation, self.groups)
</span><span class="ansi-green-intense-fg ansi-bold">    417</span> 
<span class="ansi-green-intense-fg ansi-bold">    418</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">RuntimeError</span>: CUDA out of memory. Tried to allocate 292.00 MiB (GPU 0; 15.78 GiB total capacity; 13.98 GiB already allocated; 290.44 MiB free; 14.33 GiB reserved in total by PyTorch)</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="mf">0.655638</span><span class="p">,</span><span class="mf">0.658692</span><span class="p">,</span><span class="mf">0.645202</span><span class="p">,</span><span class="mf">0.657674</span><span class="p">,</span><span class="mf">0.652329</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="20-epochs">20 epochs<a class="anchor-link" href="#20-epochs"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span><span class="o">=</span><span class="mf">2e-2</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">runs</span> <span class="o">=</span> <span class="mi">3</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do_train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">runs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">save_name</span><span class="o">=</span><span class="n">save_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 0
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.407063</td>
      <td>2.232776</td>
      <td>0.363197</td>
      <td>0.833800</td>
      <td>01:24</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.208278</td>
      <td>2.127079</td>
      <td>0.408755</td>
      <td>0.844235</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.142359</td>
      <td>1.986779</td>
      <td>0.468567</td>
      <td>0.867905</td>
      <td>01:24</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.084231</td>
      <td>1.931042</td>
      <td>0.483329</td>
      <td>0.878595</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.028919</td>
      <td>1.826750</td>
      <td>0.524306</td>
      <td>0.900993</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.982149</td>
      <td>2.069439</td>
      <td>0.455332</td>
      <td>0.855943</td>
      <td>01:24</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.971775</td>
      <td>1.767455</td>
      <td>0.560193</td>
      <td>0.893866</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.931995</td>
      <td>1.876334</td>
      <td>0.520998</td>
      <td>0.867396</td>
      <td>01:24</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.925326</td>
      <td>1.690644</td>
      <td>0.595062</td>
      <td>0.912191</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.900659</td>
      <td>1.690219</td>
      <td>0.586918</td>
      <td>0.899466</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.886524</td>
      <td>1.685367</td>
      <td>0.600916</td>
      <td>0.917027</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.871225</td>
      <td>1.708664</td>
      <td>0.582082</td>
      <td>0.911937</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.868201</td>
      <td>1.749729</td>
      <td>0.563757</td>
      <td>0.903029</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.856341</td>
      <td>1.622145</td>
      <td>0.623568</td>
      <td>0.916009</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.838085</td>
      <td>1.783579</td>
      <td>0.570120</td>
      <td>0.881395</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.832450</td>
      <td>1.598794</td>
      <td>0.636294</td>
      <td>0.918554</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.792964</td>
      <td>1.610491</td>
      <td>0.640621</td>
      <td>0.919572</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.751033</td>
      <td>1.499390</td>
      <td>0.677781</td>
      <td>0.922881</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.707864</td>
      <td>1.439508</td>
      <td>0.695088</td>
      <td>0.931535</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.692105</td>
      <td>1.406716</td>
      <td>0.706032</td>
      <td>0.934843</td>
      <td>01:26</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 1
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.419986</td>
      <td>2.174659</td>
      <td>0.383558</td>
      <td>0.855688</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.211269</td>
      <td>2.020864</td>
      <td>0.439043</td>
      <td>0.856452</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.145571</td>
      <td>2.330460</td>
      <td>0.336218</td>
      <td>0.815220</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.095639</td>
      <td>2.077936</td>
      <td>0.436498</td>
      <td>0.849580</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.053583</td>
      <td>1.995754</td>
      <td>0.460422</td>
      <td>0.858743</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.010163</td>
      <td>1.842373</td>
      <td>0.521507</td>
      <td>0.892594</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.975078</td>
      <td>1.854009</td>
      <td>0.522779</td>
      <td>0.899466</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.929181</td>
      <td>1.788045</td>
      <td>0.544922</td>
      <td>0.898702</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.928650</td>
      <td>1.827419</td>
      <td>0.543395</td>
      <td>0.896666</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.911756</td>
      <td>1.699966</td>
      <td>0.584373</td>
      <td>0.906592</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.897348</td>
      <td>2.004296</td>
      <td>0.501654</td>
      <td>0.887503</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.879381</td>
      <td>1.639879</td>
      <td>0.602698</td>
      <td>0.915500</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.871955</td>
      <td>1.770497</td>
      <td>0.570374</td>
      <td>0.884958</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.857082</td>
      <td>1.739310</td>
      <td>0.595571</td>
      <td>0.906592</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.843780</td>
      <td>1.747717</td>
      <td>0.590990</td>
      <td>0.911682</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.823137</td>
      <td>1.814982</td>
      <td>0.562993</td>
      <td>0.887758</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.798626</td>
      <td>1.650747</td>
      <td>0.628913</td>
      <td>0.911937</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.751606</td>
      <td>1.524934</td>
      <td>0.666327</td>
      <td>0.931789</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.713982</td>
      <td>1.465156</td>
      <td>0.688725</td>
      <td>0.933825</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.691586</td>
      <td>1.429835</td>
      <td>0.704505</td>
      <td>0.935607</td>
      <td>01:26</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 2
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.415290</td>
      <td>2.196582</td>
      <td>0.377704</td>
      <td>0.812930</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.221364</td>
      <td>2.205705</td>
      <td>0.364215</td>
      <td>0.826419</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.175972</td>
      <td>2.410903</td>
      <td>0.373377</td>
      <td>0.843472</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.099854</td>
      <td>2.155001</td>
      <td>0.413591</td>
      <td>0.864342</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.041411</td>
      <td>1.972753</td>
      <td>0.473403</td>
      <td>0.850344</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.005029</td>
      <td>1.849812</td>
      <td>0.508781</td>
      <td>0.892594</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.971807</td>
      <td>1.707319</td>
      <td>0.566302</td>
      <td>0.917536</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.939524</td>
      <td>1.882072</td>
      <td>0.508272</td>
      <td>0.870705</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.928395</td>
      <td>1.785622</td>
      <td>0.557903</td>
      <td>0.894375</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.916082</td>
      <td>1.806289</td>
      <td>0.550522</td>
      <td>0.887503</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.888587</td>
      <td>1.741047</td>
      <td>0.578773</td>
      <td>0.895139</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.879256</td>
      <td>1.674358</td>
      <td>0.607279</td>
      <td>0.904556</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.858374</td>
      <td>1.748244</td>
      <td>0.581064</td>
      <td>0.905828</td>
      <td>01:25</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.863942</td>
      <td>1.649715</td>
      <td>0.608297</td>
      <td>0.918809</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.852140</td>
      <td>1.804897</td>
      <td>0.554594</td>
      <td>0.892594</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.830321</td>
      <td>1.637661</td>
      <td>0.629422</td>
      <td>0.929244</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.800771</td>
      <td>1.541566</td>
      <td>0.655129</td>
      <td>0.925426</td>
      <td>01:27</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.755014</td>
      <td>1.516422</td>
      <td>0.662255</td>
      <td>0.927971</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.711990</td>
      <td>1.463601</td>
      <td>0.688725</td>
      <td>0.933825</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.692743</td>
      <td>1.439680</td>
      <td>0.692288</td>
      <td>0.937898</td>
      <td>01:26</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="mf">0.711631</span><span class="p">,</span> <span class="mf">0.705269</span><span class="p">,</span> <span class="mf">0.713413</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.7101043333333333</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="80-epochs">80 epochs<a class="anchor-link" href="#80-epochs"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">80</span>
<span class="n">runs</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do_train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">runs</span><span class="p">,</span> <span class="n">save_name</span><span class="o">=</span><span class="n">save_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Run: 0
Model loaded...
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.430797</td>
      <td>2.249969</td>
      <td>0.347417</td>
      <td>0.824637</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.214059</td>
      <td>2.098209</td>
      <td>0.415118</td>
      <td>0.847544</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.152211</td>
      <td>2.164067</td>
      <td>0.398763</td>
      <td>0.841146</td>
      <td>01:25</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-27-d601b77adcc2&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>do_train<span class="ansi-blue-fg">(</span>epochs<span class="ansi-blue-fg">,</span> runs<span class="ansi-blue-fg">,</span> save_name<span class="ansi-blue-fg">=</span>save_name<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-19-b0b8b2fa2611&gt;</span> in <span class="ansi-cyan-fg">do_train</span><span class="ansi-blue-fg">(epochs, runs, lr, size, bs, save_name)</span>
<span class="ansi-green-intense-fg ansi-bold">     14</span> 
<span class="ansi-green-intense-fg ansi-bold">     15</span>         learn<span class="ansi-blue-fg">.</span>unfreeze<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 16</span><span class="ansi-red-fg">         </span>learn<span class="ansi-blue-fg">.</span>fit_flat_cos<span class="ansi-blue-fg">(</span>epochs<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">,</span> wd<span class="ansi-blue-fg">=</span>wd<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastcore/utils.py</span> in <span class="ansi-cyan-fg">_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span>         init_args<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>log<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    471</span>         setattr<span class="ansi-blue-fg">(</span>inst<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;init_args&#39;</span><span class="ansi-blue-fg">,</span> init_args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 472</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> inst <span class="ansi-green-fg">if</span> to_return <span class="ansi-green-fg">else</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span>     <span class="ansi-green-fg">return</span> _f
<span class="ansi-green-intense-fg ansi-bold">    474</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/callback/schedule.py</span> in <span class="ansi-cyan-fg">fit_flat_cos</span><span class="ansi-blue-fg">(self, n_epoch, lr, div_final, pct_start, wd, cbs, reset_opt)</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>     lr <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>array<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>h<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;lr&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> h <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>opt<span class="ansi-blue-fg">.</span>hypers<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    136</span>     scheds <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;lr&#39;</span><span class="ansi-blue-fg">:</span> combined_cos<span class="ansi-blue-fg">(</span>pct_start<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">,</span> lr<span class="ansi-blue-fg">/</span>div_final<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">--&gt; 137</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span>n_epoch<span class="ansi-blue-fg">,</span> cbs<span class="ansi-blue-fg">=</span>ParamScheduler<span class="ansi-blue-fg">(</span>scheds<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">+</span>L<span class="ansi-blue-fg">(</span>cbs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> reset_opt<span class="ansi-blue-fg">=</span>reset_opt<span class="ansi-blue-fg">,</span> wd<span class="ansi-blue-fg">=</span>wd<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    138</span> 
<span class="ansi-green-intense-fg ansi-bold">    139</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastcore/utils.py</span> in <span class="ansi-cyan-fg">_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span>         init_args<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>log<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    471</span>         setattr<span class="ansi-blue-fg">(</span>inst<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;init_args&#39;</span><span class="ansi-blue-fg">,</span> init_args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 472</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> inst <span class="ansi-green-fg">if</span> to_return <span class="ansi-green-fg">else</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span>     <span class="ansi-green-fg">return</span> _f
<span class="ansi-green-intense-fg ansi-bold">    474</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, n_epoch, lr, wd, cbs, reset_opt)</span>
<span class="ansi-green-intense-fg ansi-bold">    205</span>             self<span class="ansi-blue-fg">.</span>opt<span class="ansi-blue-fg">.</span>set_hypers<span class="ansi-blue-fg">(</span>lr<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>lr <span class="ansi-green-fg">if</span> lr <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">else</span> lr<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    206</span>             self<span class="ansi-blue-fg">.</span>n_epoch<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>loss <span class="ansi-blue-fg">=</span> n_epoch<span class="ansi-blue-fg">,</span>tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0.</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 207</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_do_fit<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;fit&#39;</span><span class="ansi-blue-fg">,</span> CancelFitException<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>_end_cleanup<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    208</span> 
<span class="ansi-green-intense-fg ansi-bold">    209</span>     <span class="ansi-green-fg">def</span> _end_cleanup<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>xb<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>yb<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>pred<span class="ansi-blue-fg">,</span>self<span class="ansi-blue-fg">.</span>loss <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span><span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_fit</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    195</span>         <span class="ansi-green-fg">for</span> epoch <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>n_epoch<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    196</span>             self<span class="ansi-blue-fg">.</span>epoch<span class="ansi-blue-fg">=</span>epoch
<span class="ansi-green-fg">--&gt; 197</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_do_epoch<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;epoch&#39;</span><span class="ansi-blue-fg">,</span> CancelEpochException<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    198</span> 
<span class="ansi-green-intense-fg ansi-bold">    199</span>     <span class="ansi-blue-fg">@</span>log_args<span class="ansi-blue-fg">(</span>but<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;cbs&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_epoch</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    190</span>     <span class="ansi-green-fg">def</span> _do_epoch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    191</span>         self<span class="ansi-blue-fg">.</span>_do_epoch_train<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 192</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_do_epoch_validate<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    193</span> 
<span class="ansi-green-intense-fg ansi-bold">    194</span>     <span class="ansi-green-fg">def</span> _do_fit<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_do_epoch_validate</span><span class="ansi-blue-fg">(self, ds_idx, dl)</span>
<span class="ansi-green-intense-fg ansi-bold">    186</span>         <span class="ansi-green-fg">if</span> dl <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span> dl <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dls<span class="ansi-blue-fg">[</span>ds_idx<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    187</span>         self<span class="ansi-blue-fg">.</span>dl <span class="ansi-blue-fg">=</span> dl
<span class="ansi-green-fg">--&gt; 188</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">with</span> torch<span class="ansi-blue-fg">.</span>no_grad<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>_with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>all_batches<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;validate&#39;</span><span class="ansi-blue-fg">,</span> CancelValidException<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    189</span> 
<span class="ansi-green-intense-fg ansi-bold">    190</span>     <span class="ansi-green-fg">def</span> _do_epoch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">_with_events</span><span class="ansi-blue-fg">(self, f, event_type, ex, final)</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span> 
<span class="ansi-green-intense-fg ansi-bold">    154</span>     <span class="ansi-green-fg">def</span> _with_events<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> f<span class="ansi-blue-fg">,</span> event_type<span class="ansi-blue-fg">,</span> ex<span class="ansi-blue-fg">,</span> final<span class="ansi-blue-fg">=</span>noop<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 155</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>       self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;before_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>       <span class="ansi-blue-fg">;</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    156</span>         <span class="ansi-green-fg">except</span> ex<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_cancel_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#39;after_{event_type}&#39;</span><span class="ansi-blue-fg">)</span>        <span class="ansi-blue-fg">;</span>final<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/learner.py</span> in <span class="ansi-cyan-fg">all_batches</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    159</span>     <span class="ansi-green-fg">def</span> all_batches<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    160</span>         self<span class="ansi-blue-fg">.</span>n_iter <span class="ansi-blue-fg">=</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 161</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">for</span> o <span class="ansi-green-fg">in</span> enumerate<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>one_batch<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>o<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span> 
<span class="ansi-green-intense-fg ansi-bold">    163</span>     <span class="ansi-green-fg">def</span> _do_one_batch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/fastai/data/load.py</span> in <span class="ansi-cyan-fg">__iter__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    101</span>         self<span class="ansi-blue-fg">.</span>randomize<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    102</span>         self<span class="ansi-blue-fg">.</span>before_iter<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 103</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">for</span> b <span class="ansi-green-fg">in</span> _loaders<span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>fake_l<span class="ansi-blue-fg">.</span>num_workers<span class="ansi-blue-fg">==</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>fake_l<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    104</span>             <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>device <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span> b <span class="ansi-blue-fg">=</span> to_device<span class="ansi-blue-fg">(</span>b<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    105</span>             <span class="ansi-green-fg">yield</span> self<span class="ansi-blue-fg">.</span>after_batch<span class="ansi-blue-fg">(</span>b<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    361</span> 
<span class="ansi-green-intense-fg ansi-bold">    362</span>     <span class="ansi-green-fg">def</span> __next__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 363</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    364</span>         self<span class="ansi-blue-fg">.</span>_num_yielded <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    365</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_dataset_kind <span class="ansi-blue-fg">==</span> _DatasetKind<span class="ansi-blue-fg">.</span>Iterable <span class="ansi-green-fg">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">\</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    972</span> 
<span class="ansi-green-intense-fg ansi-bold">    973</span>             <span class="ansi-green-fg">assert</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>_shutdown <span class="ansi-green-fg">and</span> self<span class="ansi-blue-fg">.</span>_tasks_outstanding <span class="ansi-blue-fg">&gt;</span> <span class="ansi-cyan-fg">0</span>
<span class="ansi-green-fg">--&gt; 974</span><span class="ansi-red-fg">             </span>idx<span class="ansi-blue-fg">,</span> data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_get_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    975</span>             self<span class="ansi-blue-fg">.</span>_tasks_outstanding <span class="ansi-blue-fg">-=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    976</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_get_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    939</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    940</span>             <span class="ansi-green-fg">while</span> <span class="ansi-green-fg">True</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 941</span><span class="ansi-red-fg">                 </span>success<span class="ansi-blue-fg">,</span> data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_try_get_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    942</span>                 <span class="ansi-green-fg">if</span> success<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    943</span>                     <span class="ansi-green-fg">return</span> data

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_try_get_data</span><span class="ansi-blue-fg">(self, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    777</span>         <span class="ansi-red-fg">#   (bool: whether successfully get data, any: data if successful else None)</span>
<span class="ansi-green-intense-fg ansi-bold">    778</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 779</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_data_queue<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span>timeout<span class="ansi-blue-fg">=</span>timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    780</span>             <span class="ansi-green-fg">return</span> <span class="ansi-blue-fg">(</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    781</span>         <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/multiprocessing/queues.py</span> in <span class="ansi-cyan-fg">get</span><span class="ansi-blue-fg">(self, block, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    102</span>                 <span class="ansi-green-fg">if</span> block<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    103</span>                     timeout <span class="ansi-blue-fg">=</span> deadline <span class="ansi-blue-fg">-</span> time<span class="ansi-blue-fg">.</span>monotonic<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 104</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>_poll<span class="ansi-blue-fg">(</span>timeout<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    105</span>                         <span class="ansi-green-fg">raise</span> Empty
<span class="ansi-green-intense-fg ansi-bold">    106</span>                 <span class="ansi-green-fg">elif</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>_poll<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/multiprocessing/connection.py</span> in <span class="ansi-cyan-fg">poll</span><span class="ansi-blue-fg">(self, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    255</span>         self<span class="ansi-blue-fg">.</span>_check_closed<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    256</span>         self<span class="ansi-blue-fg">.</span>_check_readable<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 257</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_poll<span class="ansi-blue-fg">(</span>timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    258</span> 
<span class="ansi-green-intense-fg ansi-bold">    259</span>     <span class="ansi-green-fg">def</span> __enter__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/multiprocessing/connection.py</span> in <span class="ansi-cyan-fg">_poll</span><span class="ansi-blue-fg">(self, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    412</span> 
<span class="ansi-green-intense-fg ansi-bold">    413</span>     <span class="ansi-green-fg">def</span> _poll<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> timeout<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 414</span><span class="ansi-red-fg">         </span>r <span class="ansi-blue-fg">=</span> wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span>         <span class="ansi-green-fg">return</span> bool<span class="ansi-blue-fg">(</span>r<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    416</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/multiprocessing/connection.py</span> in <span class="ansi-cyan-fg">wait</span><span class="ansi-blue-fg">(object_list, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    918</span> 
<span class="ansi-green-intense-fg ansi-bold">    919</span>             <span class="ansi-green-fg">while</span> <span class="ansi-green-fg">True</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 920</span><span class="ansi-red-fg">                 </span>ready <span class="ansi-blue-fg">=</span> selector<span class="ansi-blue-fg">.</span>select<span class="ansi-blue-fg">(</span>timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    921</span>                 <span class="ansi-green-fg">if</span> ready<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    922</span>                     <span class="ansi-green-fg">return</span> <span class="ansi-blue-fg">[</span>key<span class="ansi-blue-fg">.</span>fileobj <span class="ansi-green-fg">for</span> <span class="ansi-blue-fg">(</span>key<span class="ansi-blue-fg">,</span> events<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">in</span> ready<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/selectors.py</span> in <span class="ansi-cyan-fg">select</span><span class="ansi-blue-fg">(self, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    413</span>         ready <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 415</span><span class="ansi-red-fg">             </span>fd_event_list <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_selector<span class="ansi-blue-fg">.</span>poll<span class="ansi-blue-fg">(</span>timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    416</span>         <span class="ansi-green-fg">except</span> InterruptedError<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span>             <span class="ansi-green-fg">return</span> ready

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="200-epochs">200 epochs<a class="anchor-link" href="#200-epochs"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">runs</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do_train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">runs</span><span class="p">,</span> <span class="n">save_name</span><span class="o">=</span><span class="n">save_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

