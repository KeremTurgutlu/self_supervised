{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Utilities for creating torch Modules for self supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://github.com/rwightman/pytorch-image-models/blob/3a7aa95f7e5fc90a6a2683c756e854e26201d82e/timm/models/layers/adaptive_avgmax_pool.py#L79\n",
    "mk_class('PoolingType', **{o:o.lower() for o in ['Fast', 'Avg', 'AvgMax', 'CatAvgMax', 'Max']},\n",
    "         doc=\"All possible pooling types as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['PoolingType', '_splitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_fastai_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Create timm encoder from a given arch backbone\"\n",
    "    encoder = create_body(arch, n_in, pretrained, cut=None)\n",
    "    pool = AdaptiveConcatPool2d() if pool_type == \"catavgmax\" else nn.AdaptiveAvgPool2d(1)\n",
    "    return nn.Sequential(*encoder, pool, Flatten())\n",
    "\n",
    "def create_timm_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Creates a body from any model in the `timm` library. If pool_type is None then it uses timm default\"\n",
    "    if ('vit' in arch) or (pool_type is None):\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0)\n",
    "    else:\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0, global_pool=pool_type)\n",
    "    return model\n",
    "\n",
    "def create_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"A utility for creating encoder without specifying the package\"\n",
    "    if arch in globals(): return create_fastai_encoder(globals()[arch], pretrained, n_in, pool_type)\n",
    "    else:                 return create_timm_encoder(arch, pretrained, n_in, pool_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((1,3,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai encoder expects a function as it's first argument, where timm expects a string. Also, fastai defaults to concat pooling, aka `catavgmax` in timm. With timm's selective pooling any `PoolingType` can used. Experiments show that concat pooling is better on average so it is set as our default.\n",
    "\n",
    "For any other `pool_type` fastai uses `AdaptiveAvgPool2d`, for timm you can choose from the remaining `PoolingType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34, pool_type=False)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"xresnet34\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision Transformer is a special case which uses `Layernorm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model = create_timm_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = vit_model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mlp_module(dim,hidden_size,projection_size,bn=False,nlayers=2):\n",
    "    \"MLP module as described in papers, used as projection layer\"\n",
    "    l = []\n",
    "    for i in range(nlayers-1):\n",
    "        l += [nn.Linear(dim, hidden_size) if i == 0 else nn.Linear(hidden_size, hidden_size)] \n",
    "        if bn: l += [nn.BatchNorm1d(hidden_size)]\n",
    "        l += [nn.ReLU(inplace=True)]\n",
    "    ls = l + [nn.Linear(hidden_size, projection_size)]\n",
    "    return nn.Sequential(*ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR\n",
    "create_mlp_module(1024,4096,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR-v2\n",
    "create_mlp_module(1024,4096,128,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BYOL\n",
    "create_mlp_module(1024,4096,128,bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SWAV\n",
    "create_mlp_module(1024,4096,128,bn=True,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_cls_module(nf, n_out, lin_ftrs=None, ps=0.5, use_bn=True, first_bn=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Creates classification layer which takes nf flatten features and outputs n_out logits\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [use_bn]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((2,3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"xresnet34\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7114, -0.5847,  0.7918,  0.3261,  0.2050],\n",
      "        [ 0.6052, -0.6912, -0.8514, -0.1103,  0.6599]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8229,  0.7023,  0.1985,  0.3196,  0.7406],\n",
      "        [ 0.3516, -1.4291,  0.0601, -0.2795, -0.3537]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_model` can be used to create models for classification, for example quickly creating a model for downstream classification training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(create_cls_module)\n",
    "def create_model(arch, n_out, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax, **kwargs):\n",
    "    encoder = create_encoder(arch, pretrained=pretrained, n_in=n_in, pool_type=pool_type)\n",
    "    sz = int(arch.split(\"_\")[-1]) if 'vit'in arch else 224\n",
    "    with torch.no_grad(): nf = encoder(torch.randn(2,3,sz,sz)).size(-1)\n",
    "    head = create_cls_module(nf, n_out, **kwargs)\n",
    "    apply_init(head)\n",
    "    model = nn.Sequential(encoder, head)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_splitter` can be passed to `Learner(...,splitter=splitter_func)`. This can be used to freeze or unfreeze encoder layers, in this case first parameter group is the encoder and second parameter group is the classification head. Simply by indexing to model[0] and model[1] we can access encoder and classification head modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _splitter(m): return L(m[0], m[1]).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25, inplace=False)\n",
       "  (2): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=512, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"xresnet34\", 10, pretrained=False)\n",
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5237, -0.2880, -1.9439,  3.4208, -0.1666, -3.4264,  3.9461,  1.0382,\n",
      "         -2.6832,  1.5683],\n",
      "        [-1.5816,  1.5053,  4.6323, -5.8435, -1.6473,  2.7991, -2.3200,  0.5509,\n",
      "          0.8251,  2.6881]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.25, inplace=False)\n",
       "  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"vit_large_patch16_384\", 10, pretrained=False, use_bn=False, first_bn=False, bn_final=False)\n",
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3602,  1.3346,  1.3210,  3.4194,  2.9807,  0.1214, -4.8326,  1.6076,\n",
      "          3.6632,  4.2387],\n",
      "        [ 2.5722, -0.4983,  0.5716, -0.9581, -1.7126,  1.6909,  0.0528,  0.9138,\n",
      "         -0.6740, -0.1348]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01-augmentations.ipynb.\n",
      "Converted 02-layers.ipynb.\n",
      "Converted 10-simclr.ipynb.\n",
      "Converted 10b-simclr_v2.ipynb.\n",
      "Converted 20-byol.ipynb.\n",
      "Converted 30-swav.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
