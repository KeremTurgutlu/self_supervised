{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Utilities for creating torch Modules for self supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://github.com/rwightman/pytorch-image-models/blob/3a7aa95f7e5fc90a6a2683c756e854e26201d82e/timm/models/layers/adaptive_avgmax_pool.py#L79\n",
    "mk_class('PoolType', **{o:o.lower() for o in ['Fast', 'Avg', 'AvgMax', 'CatAvgMax', 'Max']},\n",
    "         doc=\"All possible pooling types as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_fastai_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolType.CatAvgMax):\n",
    "    \"Create timm encoder from a given arch backbone\"\n",
    "    encoder = create_body(arch, n_in, pretrained, cut=None)\n",
    "    pool = AdaptiveConcatPool2d() if pool_type == \"catavgmax\" else nn.AdaptiveAvgPool2d(1)\n",
    "    return nn.Sequential(*encoder, pool, Flatten())\n",
    "\n",
    "def create_timm_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolType.CatAvgMax):\n",
    "    \"Creates a body from any model in the `timm` library. If pool_type is None then it uses timm default\"\n",
    "    if ('vit' in arch) or (pool_type is None):\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0)\n",
    "    else:\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0, global_pool=pool_type)\n",
    "    return model\n",
    "\n",
    "def create_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolType.CatAvgMax):\n",
    "    \"A utility for creating encoder without specifying the package\"\n",
    "    if arch in globals(): return create_fastai_encoder(globals()[arch], pretrained, n_in, pool_type)\n",
    "    else:                 return create_timm_encoder(arch, pretrained, n_in, pool_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((1,3,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai encoder expects a function as it's first argument, where timm expects a string. Also, fastai defaults to concat pooling, aka `catavgmax` in timm. With timm's selective pooling any `PoolType` can used. Experiments show that concat pooling is better on average so it is set as our default.\n",
    "\n",
    "For any other `pool_type` fastai uses `AdaptiveAvgPool2d`, for timm you can choose from the remaining `PoolType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34, pool_type=False)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"xresnet34\", pretrained=False, pool_type=PoolType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision Transformer is a special case which uses `Layernorm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model = create_timm_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = vit_model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mlp_module(dim,hidden_size,projection_size,bn=False,nlayers=2):\n",
    "    \"MLP module as described in papers, used as projection layer\"\n",
    "    l = []\n",
    "    for i in range(nlayers-1):\n",
    "        l += [nn.Linear(dim, hidden_size) if i == 0 else nn.Linear(hidden_size, hidden_size)] \n",
    "        if bn: l += [nn.BatchNorm1d(hidden_size)]\n",
    "        l += [nn.ReLU(inplace=True)]\n",
    "    ls = l + [nn.Linear(hidden_size, projection_size)]\n",
    "    return nn.Sequential(*ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR\n",
    "create_mlp_module(1024,4096,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR-v2\n",
    "create_mlp_module(1024,4096,128,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BYOL\n",
    "create_mlp_module(1024,4096,128,bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SWAV\n",
    "create_mlp_module(1024,4096,128,bn=True,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_cls_module(nf, n_out, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Creates classification layer which takes nf flatten features and outputs n_out logits\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [True]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((2,3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"xresnet34\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0195, -0.2775, -0.7257,  0.8391, -0.1943],\n",
      "        [-0.2854, -0.0407,  1.4847, -0.3034,  0.3028]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1113,  1.4554, -0.0675, -1.2252, -0.6768],\n",
      "        [-0.6076, -0.1960,  1.1632,  1.0209,  0.3946]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00-utils.ipynb.\n",
      "Converted 01-augmentations.ipynb.\n",
      "Converted 02-layers.ipynb.\n",
      "Converted 10-simclr.ipynb.\n",
      "Converted 10b-simclr_v2.ipynb.\n",
      "Converted 20-byol.ipynb.\n",
      "Converted 30-swav.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
