{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d19aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq self-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.dino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7819d1",
   "metadata": {},
   "source": [
    "# DINO\n",
    "\n",
    "> DINO: [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/pdf/2104.14294.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5619bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *\n",
    "from self_supervised.models.vision_transformer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfe642",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031300b",
   "metadata": {},
   "source": [
    "#### DINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328267e",
   "metadata": {},
   "source": [
    "![DINO Framework](images/dino.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38dd88",
   "metadata": {},
   "source": [
    "**Abstract**: In this paper, we question if self-supervised learning provides\n",
    "new properties to Vision Transformer (ViT) [18] that\n",
    "stand out compared to convolutional networks (convnets).\n",
    "Beyond the fact that adapting self-supervised methods to this\n",
    "architecture works particularly well, we make the following\n",
    "observations: first, self-supervised ViT features contain\n",
    "explicit information about the semantic segmentation of an\n",
    "image, which does not emerge as clearly with supervised\n",
    "ViTs, nor with convnets. Second, these features are also excellent\n",
    "k-NN classifiers, reaching 78.3% top-1 on ImageNet\n",
    "with a small ViT. Our study also underlines the importance of\n",
    "momentum encoder [31], multi-crop training [10], and the\n",
    "use of small patches with ViTs. We implement our findings\n",
    "into a simple self-supervised method, called DINO, which\n",
    "we interpret as a form of self-distillation with no labels.\n",
    "We show the synergy between DINO and ViTs by achieving\n",
    "80.1% top-1 on ImageNet in linear evaluation with ViT-Base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078bb31",
   "metadata": {},
   "source": [
    "**Own Summary**: In this paper authors show effectiveness of the combination of DINO framework and ViT based architectures such as ViT and DEIT. There is no contrastive training nor negative pairs, rather ideas such as momentum encoder and multi-crop augmention from `BYOL` and `SWAV` respectively are adapted. They use distillation with a teacher-student configuration, and avoid representation collapse by centering and sharpening target distributions generated by the teacher. 2 large views (~50%) are used as targets and all views (2 large, 4 small) are used for predictions similar to `SWAV`. Centering values and teacher parameters are updated via ema (exponential moving average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DINOHead(nn.Module):\n",
    "    '''\n",
    "    https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html\n",
    "    https://pytorch.org/docs/stable/generated/torch.nn.GELU.html\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, use_bn=False, norm_last_layer=True, nlayers=3, hidden_dim=2048, bottleneck_dim=256):\n",
    "        super().__init__()\n",
    "        nlayers = max(nlayers, 1)\n",
    "        if nlayers == 1:\n",
    "            self.mlp = nn.Linear(in_dim, bottleneck_dim)\n",
    "        else:\n",
    "            layers = [nn.Linear(in_dim, hidden_dim)]\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            for _ in range(nlayers - 2):\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                if use_bn:\n",
    "                    layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "                layers.append(nn.GELU())\n",
    "            layers.append(nn.Linear(hidden_dim, bottleneck_dim))\n",
    "            self.mlp = nn.Sequential(*layers)\n",
    "        self.apply(self._init_weights)\n",
    "        self.last_layer = nn.utils.weight_norm(nn.Linear(bottleneck_dim, out_dim, bias=False))\n",
    "        self.last_layer.weight_g.data.fill_(1)\n",
    "        if norm_last_layer:\n",
    "            self.last_layer.weight_g.requires_grad = False\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = nn.functional.normalize(x, dim=-1, p=2)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9477d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "x_large = [torch.randn(4,3,224,224)]*2\n",
    "x_small = [torch.randn(4,3,96,96)]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416476bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 3, 224, 224]),\n",
       " torch.Size([4, 3, 224, 224]),\n",
       " torch.Size([4, 3, 96, 96]),\n",
       " torch.Size([4, 3, 96, 96]),\n",
       " torch.Size([4, 3, 96, 96]),\n",
       " torch.Size([4, 3, 96, 96])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_large + x_small; [xi.size() for xi in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_encoder = VisionTransformer(patch_size=32, embed_dim=128, depth=4, num_heads=4, mlp_ratio=4,\n",
    "                          qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6))\n",
    "teacher_encoder = VisionTransformer(patch_size=32, embed_dim=128, depth=4, num_heads=4, mlp_ratio=4,\n",
    "                          qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_encoder = MultiCropWrapper(student_encoder)\n",
    "teacher_encoder = MultiCropWrapper(teacher_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cd74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dim = 2**10; out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_head = DINOHead(student_encoder.encoder.embed_dim, out_dim, norm_last_layer=True)\n",
    "teacher_head = DINOHead(student_encoder.encoder.embed_dim, out_dim, norm_last_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e7d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DINOHead(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=2048, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): GELU()\n",
       "    (4): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (last_layer): Linear(in_features=256, out_features=1024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf88ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(student_head.last_layer.weight, student_head.last_layer.weight_g*student_head.last_layer.weight_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = nn.Sequential(student_encoder, student_head)\n",
    "teacher_model = nn.Sequential(teacher_encoder, teacher_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.load_state_dict(student_model.state_dict());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b664eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_t in teacher_model.parameters(): param_t.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386582f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = student_model(x)\n",
    "with torch.no_grad(): \n",
    "    targs = teacher_model(x_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1aa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 1024]), torch.Size([8, 1024]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmom, tmom = 0.999,0.999\n",
    "tps,tpt = 0.4,0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ece115",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.zeros(1,out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cca0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and sharpen\n",
    "targs = F.softmax(targs - C / tpt, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharpen\n",
    "preds = F.log_softmax(preds / tps, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1024]), torch.Size([24, 1024]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_targs, n_preds = targs.size(0)//bs, preds.size(0)//bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2be729",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs1 = targs.view(bs, targs.size(0)//bs, -1)\n",
    "preds1 = preds.view(bs, preds.size(0)//bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33186b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2, 1024]), torch.Size([4, 6, 1024]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs1.shape, preds1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (-targs1.unsqueeze(2)*preds1.unsqueeze(1)).sum(-1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4593fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones_like(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa894fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0,0] = 0\n",
    "mask[1,1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e9b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9360, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[mask.bool()].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs,preds = targs.chunk(n_targs), preds.chunk(n_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aaaf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targs), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "npairs = len(targs)*(len(preds)-1) \n",
    "loss = 0\n",
    "for ti in range(len(targs)):\n",
    "    for pi in range(len(preds)):\n",
    "        if ti != pi:\n",
    "            loss += (-targs[ti]*preds[pi]).sum(-1).mean() / npairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64008673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(get_multi_aug_pipelines, but=['n', 'size', 'resize_scale'])\n",
    "def get_dino_aug_pipelines(num_crops=(2,4), crop_sizes=(224,96), min_scales=(0.4,0.05), max_scales=(1.,0.4), **kwargs): \n",
    "    aug_pipelines = []\n",
    "    for nc, size, mins, maxs in zip(num_crops, crop_sizes, min_scales, max_scales):\n",
    "        aug_pipelines += get_multi_aug_pipelines(n=nc, size=size, resize_scale=(mins,maxs), **kwargs)\n",
    "    return aug_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pipelines = get_dino_aug_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723dc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85048a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3998, 0.1460, 0.1550, 0.1327, 0.1665]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ccb188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.1447e-11, 5.1287e-11, 1.0637e-12, 3.0646e-10]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x/0.04,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e45ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9971e-01, 4.2010e-05, 7.6538e-05, 1.6240e-05, 1.5647e-04]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x/0.1,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d183891",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_teacher_temp\n",
    "teacher_temp\n",
    "warmup_teacher_temp_epochs\n",
    "nepochs =\n",
    "np.concatenate((\n",
    "            np.linspace(warmup_teacher_temp,\n",
    "                        teacher_temp, warmup_teacher_temp_epochs),\n",
    "            np.ones(nepochs - warmup_teacher_temp_epochs) * teacher_temp\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_lin(0.04,0.07,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08649d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = 0.3\n",
    "scheds = combine_scheds([pct,1-pct], [SchedLin(0.04, 0.07), SchedNo(0.07, 0.07)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [scheds(i) for i in np.linspace(0,1,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d8229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6efef257f0>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAH+NJREFUeJzt3Xt0lPW97/H3l4SE+z1cBGISQS3eUCJC5WLr1oO2u9hurHCssi0l0B732fuc09Vt9167F//Ya7nXWXXvrrrkUqiKVWyxrWmLcrzUBBQpwSug1GQCJOEe7peQ2/f8MQ/tmAYzSSZ5MjOf11qzMs/z/Obh+8uj88k8z8x3zN0RERHpFXYBIiLSMygQREQEUCCIiEhAgSAiIoACQUREAgoEEREBFAgiIhJQIIiICKBAEBGRQGbYBbTHiBEjPC8vL+wyRESSyrZt2464e05b45IqEPLy8igrKwu7DBGRpGJme+IZp1NGIiICKBBERCSgQBAREUCBICIiAQWCiIgAcQaCmc0xs11mVm5mD7WyPdvMngu2bzGzvGD9vWb2bsyt2cwmB9ummNkHwWN+bGaWyImJiEj7tBkIZpYBPAbcAUwCFpjZpBbDFgHH3H0C8CjwCIC7/9zdJ7v7ZOA+oNLd3w0e8ziwGJgY3OYkYD4iItJB8XwOYSpQ7u4RADNbC8wFdsaMmQv8ILi/DviJmZl/8vs5FwBrg32MAQa5+1vB8lPAXcCLHZ+K9AQHT9bx7B/30tysr2YVSaR/uHUivTO69ix/PIEwFqiKWa4GbrrYGHdvNLMTwHDgSMyYe4gGx4Xx1S32Oba1f9zMioAigNzc3DjKlTA98tJH/OrtGnQCUCSxvvW5CfTO6Np/o1s+qWxmNwFn3X17ex/r7iuAFQCFhYX6s7MHqzl+juJ39/HAzXl8/2+vCrscEWmneF5/1ADjY5bHBetaHWNmmcBgoDZm+3zg2Rbjx7WxT0kyqzdV4sA3ZhaEXYqIdEA8gbAVmGhm+WaWRfTJvbjFmGJgYXB/HvDahesHZtYL+CrB9QMAd98PnDSzacG7i+4HXujUTCRUJ8428Owf9/Kl6y5h7JC+YZcjIh3Q5imj4JrAg8AGIANY7e47zOxhoMzdi4FVwBozKweOEg2NC2YBVRcuSsf4FvAE0JfoxWRdUE5ia97azdn6JpbM1qsDkWQV1zUEd18PrG+x7nsx9+uAuy/y2NeBaa2sLwOubket0kPVNTTxxJu7ueWKHK4cPSjsckSkg/RJZem059+u5sjpepbMuizsUkSkExQI0ilNzc7K0gjXjR/CtIJhYZcjIp2gQJBO2bDjALtrz7J0VgHqPiKS3BQI0mHuzrKSCvJH9Of2q0aHXY6IdJICQTpsc6SW96tPsHhmARm99OpAJNkpEKTDlpdEGDEgi6/c0GrXERFJMgoE6ZCd+05S8qfDPHBzPn26usGKiHQLBYJ0yIrSCvpnZfC1my4NuxQRSRAFgrRb9bGz/Pb9/SyYmsvgfr3DLkdEEkSBIO32042VGLBoZn7YpYhIAikQpF2Onannua1VzJ08ljGD1cROJJUoEKRd1ry1h3MNamInkooUCBK3c/XRJna3XjmSy0cNDLscEUkwBYLEbd22Ko6eqWfJbDWxE0lFCgSJS2NTMys2Rrg+dwg35g0NuxwR6QIKBInLi9sPUHX0HEtnX6YmdiIpSoEgbXJ3lpdWUJDTn9s+MyrsckSkiygQpE1vlNeyveYkS2YV0EtN7ERSlgJB2rS8tIKcgdncdb2a2ImkMgWCfKrtNSfY+PERvn5zPtmZamInksoUCPKplpdGGJCdyb3TcsMuRUS6mAJBLqrq6Fl+//4+7r0pl0F91MROJNUpEOSiVm6MkNHLeOBmNbETSQcKBGlV7enz/KKsii9fP5bRg/uEXY6IdIO4AsHM5pjZLjMrN7OHWtmebWbPBdu3mFlezLZrzWyzme0wsw/MrE+w/vVgn+8Gt5GJmpR03lOb91DX0EzRLDWxE0kXmW0NMLMM4DHgNqAa2Gpmxe6+M2bYIuCYu08ws/nAI8A9ZpYJPA3c5+7vmdlwoCHmcfe6e1miJiOJcba+kSc37+ZvPjOKCSPVxE4kXcTzCmEqUO7uEXevB9YCc1uMmQs8GdxfB9xq0f4GtwPvu/t7AO5e6+5NiSldusovtlZx/GwD37xFrw5E0kk8gTAWqIpZrg7WtTrG3RuBE8Bw4HLAzWyDmb1tZt9p8bifBaeL/s0u0iDHzIrMrMzMyg4fPhxHudIZjU3NrNxYSeGlQ5ly6bCwyxGRbtTVF5UzgRnAvcHPL5vZrcG2e939GmBmcLuvtR24+wp3L3T3wpycnC4uV37/wX5qjkeb2IlIeoknEGqA8THL44J1rY4JrhsMBmqJvpoodfcj7n4WWA/cAODuNcHPU8AzRE9NSYjcnWUlESaMHMDnr9Q1fpF0E08gbAUmmlm+mWUB84HiFmOKgYXB/XnAa+7uwAbgGjPrFwTFbGCnmWWa2QgAM+sNfBHY3vnpSGeUfnyED/efpEhN7ETSUpvvMnL3RjN7kOiTewaw2t13mNnDQJm7FwOrgDVmVg4cJRoauPsxM/sR0VBxYL27/97M+gMbgjDIAF4BVnbB/KQdlpdUMGpQNndNVhM7kXTUZiAAuPt6oqd7Ytd9L+Z+HXD3RR77NNG3nsauOwNMaW+x0nXerz7OmxW1/MudV5KVqc8riqQj/Z8vACwviTCwTyYLpqqJnUi6UiAIu4+c4cXt+/natEsZqCZ2ImlLgSD8dFOEzF69eOCzeWGXIiIhUiCkuSOnz/PLsmq+csNYRg5SEzuRdKZASHNPvrmb+qZmFquJnUjaUyCksTPnG3lq8x5unzSKy3IGhF2OiIRMgZDG1m6t4sS5BrWpEBFAgZC2GpqaWbUxwtT8YVyfOzTsckSkB1AgpKnfvrePfSfqWDpb1w5EJEqBkIbcneUlEa4YNZDPXaEmdiISpUBIQ6//6TC7Dp6iaFYBF/kaChFJQwqENLTs9QrGDO7D3153SdiliEgPokBIM+/sPcaWyqMsmpGvJnYi8gl6RkgzK0ojDOqTyXw1sRORFhQIaSRy+DQv7TjA/dPzGJAdV+dzEUkjCoQ0snJjJb0zerFQTexEpBUKhDRx6FQdz79dzbwp48gZmB12OSLSAykQ0sQTb+ymoamZopn6IJqItE6BkAZOn29kzVt7uOPq0eSN6B92OSLSQykQ0sCzW/Zyqq6RJbPUxE5ELk6BkOLqG5tZtamS6QXDuW78kLDLEZEeTIGQ4orf28eBk3UsURM7EWmDAiGFNTc7y0squHL0QGZfnhN2OSLSw8UVCGY2x8x2mVm5mT3UyvZsM3su2L7FzPJitl1rZpvNbIeZfWBmfYL1U4LlcjP7sanLWsL9YdchPj50mqWzL1MTOxFpU5uBYGYZwGPAHcAkYIGZTWoxbBFwzN0nAI8CjwSPzQSeBpa6+1XALUBD8JjHgcXAxOA2p7OTkU9aVlLB2CF9+cK1Y8IuRUSSQDyvEKYC5e4ecfd6YC0wt8WYucCTwf11wK3BX/y3A++7+3sA7l7r7k1mNgYY5O5vubsDTwF3JWA+Eti25yhbdx/jGzPz6Z2hM4Mi0rZ4ninGAlUxy9XBulbHuHsjcAIYDlwOuJltMLO3zew7MeOr29indMLykghD+vXmnhvHh12KiCSJru5wlgnMAG4EzgKvmtk2ooERFzMrAooAcnPVoTMe5YdO8/KHB/mHz02gX5aa2IlIfOJ5hVADxP6ZOS5Y1+qY4LrBYKCW6F/+pe5+xN3PAuuBG4Lx49rYJwDuvsLdC929MCdH75SJx8rSCFlqYici7RRPIGwFJppZvpllAfOB4hZjioGFwf15wGvBtYENwDVm1i8IitnATnffD5w0s2nBtYb7gRcSMJ+0d/BkHb9+p4avFo5n+AA1sROR+LV5PsHdG83sQaJP7hnAanffYWYPA2XuXgysAtaYWTlwlGho4O7HzOxHREPFgfXu/vtg198CngD6Ai8GN+mk1W9U0tjczGI1sRORdorrBLO7ryd6uid23fdi7tcBd1/ksU8Tfetpy/VlwNXtKVY+3cm6Bp55ay93XjOG3OH9wi5HRJKM3o+YQp7ZspdT59XETkQ6RoGQIs43NrF6UyU3TxjONeMGh12OiCQhBUKKeOGdfRw6dZ6ls/XqQEQ6RoGQApqbnWWlFVx1ySBmTBgRdjkikqQUCCnglQ8PEjl8hiVqYicinaBASAHLSyOMG9qXO68eHXYpIpLEFAhJbuvuo2zbc4zFMwvIVBM7EekEPYMkueUlFQzt15uvFqqJnYh0jgIhiX188BSvfHiIhZ/No29WRtjliEiSUyAkseWlEfr07sX90/PCLkVEUoACIUntP3GOF96tYf6NuQzrnxV2OSKSAhQISWr1pkqaHRbNyA+7FBFJEQqEJHTiXAPPbNnLF68dw/hhamInIomhQEhCP9+yhzP1TRTNUotrEUkcBUKSqWtoYvWm3cycOIKrLlETOxFJHAVCkvn1OzUcOX2eb6qJnYgkmAIhiTQ1OytLI1wzdjDTLxsedjkikmIUCEnk5Z0HiBw5w5LZBWpiJyIJp0BIEu7O4yURcof1446rx4RdjoikIAVCkthSeZT3qo6zeFYBGb306kBEEk+BkCSWl1QwvH8Wd08ZF3YpIpKiFAhJ4KMDJ/nDrsP8/Wfz6NNbTexEpGsoEJLAipII/bIyuG/6pWGXIiIpTIHQw9UcP0fxe/uYf2MuQ/qpiZ2IdJ24AsHM5pjZLjMrN7OHWtmebWbPBdu3mFlesD7PzM6Z2bvBbVnMY14P9nlh28hETSqVrN5UiQOLZqqJnYh0rcy2BphZBvAYcBtQDWw1s2J33xkzbBFwzN0nmNl84BHgnmBbhbtPvsju73X3so6Xn9qOn63n2T/u5UvXXcLYIX3DLkdEUlw8rxCmAuXuHnH3emAtMLfFmLnAk8H9dcCtpk9OddrTb+3hbH0TS2ariZ2IdL14AmEsUBWzXB2sa3WMuzcCJ4ALvRXyzewdMysxs5ktHvez4HTRvylAPqmuoYmfvbGbW67I4crRg8IuR0TSQFdfVN4P5Lr79cD/Bp4xswvPbve6+zXAzOB2X2s7MLMiMyszs7LDhw93cbk9x7pt1dSeqWfJLDWxE5HuEU8g1ADjY5bHBetaHWNmmcBgoNbdz7t7LYC7bwMqgMuD5Zrg5yngGaKnpv6Ku69w90J3L8zJyYl3XkmtqdlZuTHCdeOHMK1gWNjliEiaiCcQtgITzSzfzLKA+UBxizHFwMLg/jzgNXd3M8sJLkpjZgXARCBiZplmNiJY3xv4IrC989NJDS9tP8Ce2rMsnaUmdiLSfdp8l5G7N5rZg8AGIANY7e47zOxhoMzdi4FVwBozKweOEg0NgFnAw2bWADQDS939qJn1BzYEYZABvAKsTPTkkpG7s6ykgvwR/bn9qtFhlyMiaaTNQABw9/XA+hbrvhdzvw64u5XHPQ8838r6M8CU9habDjZHavmg5gT//uVr1MRORLqVPqncwywriTBiQDZfuaHlG7lERLqWAqEH2bnvJKV/OswDN6uJnYh0PwVCD7KitIL+WRl87SY1sROR7qdA6CGqjp7lt+/vZ8HUXAb36x12OSKShhQIPcSqTZUYamInIuFRIPQAx87U89zWKuZOHsuYwWpiJyLhUCD0AE9t3sO5BjWxE5FwKRBCdq6+iSc37+bWK0dy+aiBYZcjImlMgRCyX26r4uiZepbMVhM7EQmXAiFEjU3NrNwY4YbcIdyYNzTsckQkzSkQQvTi9gNUHT3HktmXqYmdiIROgRCSC03sCnL6c9tnRoVdjoiIAiEsb5TXsmPfSZbMKqCXmtiJSA+gQAjJspIKcgZmc9f1amInIj2DAiEE22tOsKn8CF+/OZ/sTDWxE5GeQYEQguWlEQZkZ3LvtNywSxER+TMFQjfbW3uW37+/j3tvymVQHzWxE5GeQ4HQzX66KUJGL+OBm9XETkR6FgVCN6o9fZ5flFXx5evHMnpwn7DLERH5BAVCN3py8x7qGpopmqUmdiLS8ygQusnZ+kae2ryb2yaNYsJINbETkZ5HgdBNnttaxfGzDSxVi2sR6aEUCN2goamZn26spPDSoUy5dFjY5YiItEqB0A3Wf7CfmuPnWKoW1yLSg8UVCGY2x8x2mVm5mT3UyvZsM3su2L7FzPKC9Xlmds7M3g1uy2IeM8XMPgge82NL0Xaf0SZ2ESaMHMDnrxwZdjkiIhfVZiCYWQbwGHAHMAlYYGaTWgxbBBxz9wnAo8AjMdsq3H1ycFsas/5xYDEwMbjN6fg0eq7Sj4/w4f6TFKmJnYj0cPG8QpgKlLt7xN3rgbXA3BZj5gJPBvfXAbd+2l/8ZjYGGOTub7m7A08Bd7W7+iSwvKSCUYOyuWuymtiJSM8WTyCMBapilquDda2OcfdG4AQwPNiWb2bvmFmJmc2MGV/dxj6T3vvVx3mzopZFM/LJytTlGhHp2TK7eP/7gVx3rzWzKcBvzOyq9uzAzIqAIoDc3ORqBre8JMLAPpksmJpcdYtIeornz9YaYHzM8rhgXatjzCwTGAzUuvt5d68FcPdtQAVweTB+XBv7JHjcCncvdPfCnJycOMrtGXYfOcOL2/fztWmXMlBN7EQkCcQTCFuBiWaWb2ZZwHyguMWYYmBhcH8e8Jq7u5nlBBelMbMCohePI+6+HzhpZtOCaw33Ay8kYD49xsqNETJ79eKBz+aFXYqISFzaPGXk7o1m9iCwAcgAVrv7DjN7GChz92JgFbDGzMqBo0RDA2AW8LCZNQDNwFJ3Pxps+xbwBNAXeDG4pYTDp87zy23V/N2UsYwcpCZ2IpIc4rqG4O7rgfUt1n0v5n4dcHcrj3seeP4i+ywDrm5PscniyTd309DUzDdmqk2FiCQPvfUlwc6cjzaxu33SKC7LGRB2OSIicVMgJNjarVWcrGtUmwoRSToKhARqaGpm1cYIU/OHcX3u0LDLERFpFwVCAv32vX3sO1GnFtcikpQUCAni7iwviXDFqIF87go1sROR5KNASJDXdx1m18FTFM0qIEUbt4pIilMgJMiykgouGdyHL02+JOxSREQ6RIGQAO/sPcaWyqN8fUY+vTP0KxWR5KRnrwRYXhJhUJ9M5quJnYgkMQVCJ0UOn2bDzgPcPz2PAdld3TxWRKTrKBA6aeXGCL0zerFQTexEJMkpEDrh0Kk6nt9Ww7wp48gZmB12OSIinaJA6IQn3thNQ3MzRWpiJyIpQIHQQafqGljz1h7uuHo0eSP6h12OiEinKRA6aO0fqzhV18iSWWpiJyKpQYHQAfWNzazaVMn0guFcN35I2OWIiCSEAqEDXni3hgMn61iiJnYikkIUCO3U3OysKI1w5eiBzL48J+xyREQSRoHQTq99dIiPD51m6ezL1MRORFKKAqGdlpdWMHZIX75w7ZiwSxERSSgFQjts23OUrbuP8Y2ZamInIqlHz2rtsKwkwpB+vbnnxvFhlyIiknAKhDiVHzrNyzsPcv+0S+mXpSZ2IpJ6FAhxWlkaITtTTexEJHXFFQhmNsfMdplZuZk91Mr2bDN7Lti+xczyWmzPNbPTZvbtmHW7zewDM3vXzMo6O5GudPBkHb9+p4avFo5n+AA1sROR1NRmIJhZBvAYcAcwCVhgZpNaDFsEHHP3CcCjwCMttv8IeLGV3X/O3Se7e2G7K+9Gq9+opLG5mcVqYiciKSyeVwhTgXJ3j7h7PbAWmNtizFzgyeD+OuBWC96kb2Z3AZXAjsSU3L1O1jXwzFt7ufOaMeQO7xd2OSIiXSaeQBgLVMUsVwfrWh3j7o3ACWC4mQ0A/hn4YSv7deD/mdk2Mytqb+Hd5Zktezl1vpGls9XETkRSW1e/XeYHwKPufrqVT/XOcPcaMxsJvGxmH7l7actBQVgUAeTmdu93Fp9vbGL1pkpmTBjB1WMHd+u/LSLS3eJ5hVADxL7xflywrtUxZpYJDAZqgZuA/zCz3cA/Af9iZg8CuHtN8PMQ8Guip6b+iruvcPdCdy/Myene3kG/eaeGQ6fOq4mdiKSFeAJhKzDRzPLNLAuYDxS3GFMMLAzuzwNe86iZ7p7n7nnAfwL/7u4/MbP+ZjYQwMz6A7cD2xMwn4RpbnaWl0a46pJBzJgwIuxyRES6XJunjNy9MfirfgOQAax29x1m9jBQ5u7FwCpgjZmVA0eJhsanGQX8OjiNlAk84+4vdWIeCffKhweJHD7DjxdcryZ2IpIWzN3DriFuhYWFXlbW9R9ZcHf+7vE3OXTqPK9/+xYy1bdIRJKYmW2L5+39eqZrRdmeY7y99ziLZxYoDEQkbejZrhXLXq9gaL/efLVQTexEJH0oEFr408FTvPrRIRZ+No++WRlhlyMi0m0UCC2sKI3Qt3cGC6fnhV2KiEi3UiDE2H/iHC+8W8M9N45naP+ssMsREelWCoQYqzdV0uywaEZ+2KWIiHQ7BULgxLkGntmyly9eO4bxw9TETkTSjwIh8PRbezhT30TRLLWpEJH0pEAA6hqa+Nkbu5k5cQRXXaImdiKSnhQIwK/eruHI6fN8Uy2uRSSNpX0gNDU7KzdGuGbsYKZfNjzsckREQpP2gfDyzgNUHjnD0tmXqYmdiKS1tA4Ed+fxkgi5w/ox5+rRYZcjIhKqtA6ELZVHea/qOItnFZDRS68ORCS9pXUgLC+pYHj/LO6eMi7sUkREQpe2gfDRgZP8Yddh/v6zefTprSZ2IiJpGwgrSiL0y8rgvumXhl2KiEiPkJaBUHP8HMXv7WP+jbkM6acmdiIikKaBsGpjJQ4smqkmdiIiF6RdIBw/W8/arXv50nWXMHZI37DLERHpMdIuENZs3sPZ+iaWzFYTOxGRWGkVCHUNTTzx5m5uuSKHK0cPCrscEZEeJa0CYd22amrP1LNUTexERP5K2gTChSZ2140fwk35w8IuR0Skx4krEMxsjpntMrNyM3uole3ZZvZcsH2LmeW12J5rZqfN7Nvx7jPRXtp+gD21Z1k6q0BN7EREWtFmIJhZBvAYcAcwCVhgZpNaDFsEHHP3CcCjwCMttv8IeLGd+0wYd2dZSQX5I/pz+1VqYici0pp4XiFMBcrdPeLu9cBaYG6LMXOBJ4P764BbLfgz3MzuAiqBHe3cZ8Jsrqjlg5oTLJ6pJnYiIhcTTyCMBapilquDda2OcfdG4AQw3MwGAP8M/LAD+0yYZaURRgzI5is3dNk/ISKS9DK7eP8/AB5199MdPW9vZkVAEUBubm67H9/U7FwxagC3XJ6jJnYiIp8inkCoAcbHLI8L1rU2ptrMMoHBQC1wEzDPzP4DGAI0m1kdsC2OfQLg7iuAFQCFhYUeR72fkNHL+NcvdNnlCRGRlBFPIGwFJppZPtEn7fnAf28xphhYCGwG5gGvubsDMy8MMLMfAKfd/SdBaLS1TxER6UZtBoK7N5rZg8AGIANY7e47zOxhoMzdi4FVwBozKweOEn2Cb/c+OzkXERHpBIv+IZ8cCgsLvaysLOwyRESSipltc/fCtsalzSeVRUTk0ykQREQEUCCIiEhAgSAiIoACQUREAkn1LiMzOwzs6eDDRwBHElhOMtCc04PmnB46M+dL3T2nrUFJFQidYWZl8bztKpVozulBc04P3TFnnTISERFAgSAiIoF0CoQVYRcQAs05PWjO6aHL55w21xBEROTTpdMrBBER+RQpHwhmNsfMdplZuZk9FHY9iWJm483sD2a208x2mNk/BuuHmdnLZvZx8HNosN7M7MfB7+F9M7sh3Bl0nJllmNk7Zva7YDnfzLYEc3vOzLKC9dnBcnmwPS/MujvKzIaY2Toz+8jMPjSz6al+nM3sfwX/XW83s2fNrE+qHWczW21mh8xse8y6dh9XM1sYjP/YzBZ2pqaUDgQzywAeA+4AJgELzCxVvi2nEfg/7j4JmAb8j2BuDwGvuvtE4NVgGaK/g4nBrQh4vPtLTph/BD6MWX6E6DfzTQCOAYuC9YuAY8H6R4Nxyei/gJfc/UrgOqJzT9njbGZjgf8JFLr71URb5M8n9Y7zE8CcFuvadVzNbBjwfaJfRjYV+P6FEOkQd0/ZGzAd2BCz/F3gu2HX1UVzfQG4DdgFjAnWjQF2BfeXAwtixv95XDLdiH673qvA54HfAUb0wzqZLY850e/bmB7czwzGWdhzaOd8BwOVLetO5ePMX75zfVhw3H4H/LdUPM5AHrC9o8cVWAAsj1n/iXHtvaX0KwT+8h/WBdXBupQSvES+HtgCjHL3/cGmA8Co4H6q/C7+E/gO0BwsDweOu3tjsBw7rz/POdh+IhifTPKBw8DPgtNkPzWz/qTwcXb3GuD/AnuB/USP2zZS+zhf0N7jmtDjneqBkPLMbADwPPBP7n4ydptH/2RImbeRmdkXgUPuvi3sWrpRJnAD8Li7Xw+c4S+nEYCUPM5DgblEw/ASoD9/fWol5YVxXFM9EGqA8THL44J1KcHMehMNg5+7+6+C1QfNbEywfQxwKFifCr+Lm4EvmdluYC3R00b/BQwJvqcbPjmvP8852D4YqO3OghOgGqh29y3B8jqiAZHKx/lvgEp3P+zuDcCviB77VD7OF7T3uCb0eKd6IGwFJgbvTsgiemGqOOSaEsLMjOh3WX/o7j+K2VQMXHinwUKi1xYurL8/eLfCNOBEzEvTpODu33X3ce6eR/RYvubu9wJ/AOYFw1rO+cLvYl4wPqn+knb3A0CVmV0RrLoV2EkKH2eip4qmmVm/4L/zC3NO2eMco73HdQNwu5kNDV5Z3R6s65iwL6p0w0WbO4E/ARXAv4ZdTwLnNYPoy8n3gXeD251Ez52+CnwMvAIMC8Yb0XdcVQAfEH0HR+jz6MT8bwF+F9wvAP4IlAO/BLKD9X2C5fJge0HYdXdwrpOBsuBY/wYYmurHGfgh8BGwHVgDZKfacQaeJXqNpIHoK8FFHTmuwNeDuZcDD3SmJn1SWUREgNQ/ZSQiInFSIIiICKBAEBGRgAJBREQABYKIiAQUCCIiAigQREQkoEAQEREA/j8cbKXXNKXGRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DINO(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, aug_pipelines, large_crop_ids=[0,1],\n",
    "                         cmom=0.9, tmom=0.996,\n",
    "                         tpt_start=0.04, tpt_warmup_pct=0.3, tpt_sched=SchedLin, tpt_end=0.07,\n",
    "                         tps=0.1,\n",
    "                         print_augs=False):\n",
    "        \"\"\"\n",
    "        Refer to original repo: \n",
    "        https://github.com/facebookresearch/dino/blob/0be6e112dd579203caaa1d0f066e29ca536f76dd/main_dino.py#L41\n",
    "            cmom:           Center update momentum.\n",
    "            tmom:           Teacher update momentum. Set larger, e.g. 0.9995, for small batches.\n",
    "            tpt_warmup:     Warm up starting temperature\n",
    "            tpt_warmup_pct: Percentage of training for warmup\n",
    "            tpt_sched:      Warm up scheduler, e.g. SchedLin, SchedCos, SchedExp\n",
    "            tpt:            Teacher temperature after warm up. Decrease if training loss does not decrease.\n",
    "                            Smaller temperature means more sharpening.\n",
    "            tps:            Student temperature.\n",
    "        \"\"\"\n",
    "        store_attr('large_crop_ids,cmom,tmom,tps')\n",
    "        self.augs = aug_pipelines\n",
    "        self.tpt_scheduler = combine_scheds([tpt_warmup_pct,1-tpt_warmup_pct],\n",
    "                                            [tpt_sched(tpt_start,tpt_end),SchedNo(tpt_end,tpt_end)])\n",
    "        if print_augs: \n",
    "            for aug in self.augs: print(aug)\n",
    "    \n",
    "    def before_fit(self):\n",
    "        \"Create teacher model as a copy of student\"\n",
    "        self.teacher_model = deepcopy(self.learn.model).to(self.dls.device)\n",
    "        for param_t in self.teacher_model.parameters(): param_t.requires_grad = False \n",
    "        self.learn.loss_func = self.lf\n",
    "        self.C = torch.zeros(1,num_features_model(self.learn.model))\n",
    "        self.tpt = self.tpt_scheduler(0.)\n",
    "    \n",
    "    def before_train(self):    self.teacher_model.train()\n",
    "    def before_validate(self): self.teacher_model.eval()\n",
    "    def before_batch(self):\n",
    "        \"Augment multi crop views\"\n",
    "        self.bs = self.x.size(0)\n",
    "        self.learn.xb = ([aug(self.x) for aug in self.augs],)\n",
    "        x_large = [self.learn.xb[0][i] for i in self.large_crop_ids]\n",
    "        self.cb = torch.cat(x_large).mean(0)\n",
    "        with torch.no_grad(): self.yb = (self.teacher_model(x_large),)\n",
    "\n",
    "            \n",
    "    def _momentum_update_teacher(self):\n",
    "        for param_q, param_t in zip(self.learn.model.parameters(), self.teacher_model.parameters()):\n",
    "            param_t.data = param_t.data * self.tmom + param_t.data * (1. - self.tmom)\n",
    "    \n",
    "    \n",
    "    def _momentum_update_center(self):\n",
    "        self.C = self.C*self.cmom + self.cb*(1-self.cmom)\n",
    "            \n",
    "            \n",
    "    def after_step(self):\n",
    "        \"Center and teacher updates\"\n",
    "        self._momentum_update_center()\n",
    "        self._momentum_update_teacher()\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        \"Update tpt at the end of each epoch\"\n",
    "        self.tpt = self.tpt_scheduler(self.pct_train)\n",
    "\n",
    "        \n",
    "    def lf(self, pred, *yb):\n",
    "        \"Multi crop cross entropy loss: -qlog(p)\"\n",
    "        pred = F.log_softmax(pred / self.tps, dim=-1)\n",
    "        yb   = F.softmax(yb - self.C / self.tpt, dim=-1)\n",
    "        \n",
    "        n_targs, n_preds = yb.size(0)//bs, pred.size(0)//bs\n",
    "        yb,pred = yb.chunk(n_targs), pred.chunk(n_preds)\n",
    "\n",
    "        loss, npairs = 0, len(targs)*(len(preds)-1) \n",
    "        for ti in range(len(targs)):\n",
    "            for pi in range(len(preds)):\n",
    "                if ti != pi:\n",
    "                    loss += (-targs[ti]*preds[pi]).sum(-1).mean() / npairs\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        xbs = self.learn.xb[0]\n",
    "        idxs = np.random.choice(range(self.bs), n, False)\n",
    "        images = [aug.decode(xb.to('cpu').clone()).clamp(0, 1)[i] \n",
    "                  for i in idxs\n",
    "                  for xb, aug in zip(xbs, self.augs)]\n",
    "        return show_batch(images[0], None, images, max_n=len(images), nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a72a6",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14122e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01 - augmentations.ipynb.\n",
      "Converted 02 - layers.ipynb.\n",
      "Converted 03 - distributed.ipynb.\n",
      "Converted 10 - simclr.ipynb.\n",
      "Converted 11 - moco.ipynb.\n",
      "Converted 12 - byol.ipynb.\n",
      "Converted 13 - swav.ipynb.\n",
      "Converted 14 - barlow_twins.ipynb.\n",
      "Converted 15 - dino.ipynb.\n",
      "Converted 20 - clip.ipynb.\n",
      "Converted 21 - clip-moco.ipynb.\n",
      "Converted 70 - vision.metrics.ipynb.\n",
      "Converted 90 - models.vision_transformer.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
