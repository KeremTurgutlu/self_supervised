{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.simclr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR\n",
    "\n",
    "> **SimCLR**: [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)\n",
    "\n",
    "> **SimCLR V2**: [Big Self-Supervised Models are Strong Semi-Supervised Learners](https://arxiv.org/pdf/2006.10029.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimCLR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SimCLR Framework](images/simclr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimCLR is a simple contrastive learning framework which uses 2 augmented views of the same image and InfoNCE loss for training. Different views of the same image are considered as positive examples whereas all the other images images in a batch are considered as negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimCLR V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SimCLR V2 Framework](images/simclr_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimCLR has a follow up paper with few minor changes and improvements. Code difference between `SimCLR` and `SimCLR V2` are minimal and there is good amount of overlap, that is why both versions are implemented here in the same module. Also, SimCLR V2 is more about the added step of knowledge distillation rather than the contrastive learning itself.\n",
    "\n",
    " - One difference in SimCLR V2 is that `MLP` module has 3 layers instead of 2.\n",
    "\n",
    " - Another difference is using a larger model for the pretraining/self supervised learning task. It is mentioned in the original paper that scaling up the model from ResNet-50 to ResNet-152 (3×+SK) gave 29% relative gain in top-1 accuracy when fine tuning with only 1% labeled data.\n",
    "\n",
    "- Also, a few addition to data augmentation pipeline happenned, such as adding gaussian blur.\n",
    "\n",
    "*Note that `self_supervised.augmentations` module is highly flexible, supporting all the augmentations from the popular self supervised learning algorithms by default, allowing to pass any custom augmentations and more. It should always be adjusted based on the data and problem at hand for best performance.*\n",
    "\n",
    "\n",
    "> **Qote from SimCLR V2 paper:** In our experiments, we set the width of projection head’s middle layers to that of its input, so it is also adjusted by the width multiplier. However, a wider projection head improves performance even when the base network remains narrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimCLR model consists of an `encoder` and a `projector (MLP)` layer. The definition of this module is fairly simple as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SimCLRModel(Module):\n",
    "    \"Compute predictions of concatenated xi and xj\" \n",
    "    def __init__(self,encoder,projector): self.encoder,self.projector = encoder,projector\n",
    "    def forward(self,x): return self.projector(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly using `SimCLRModel` by passing both an `encoder` and a `projector`, `create_simclr_model` function can be used by minimally passing a predefined `encoder` and the expected input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_simclr_model(encoder, hidden_size=256, projection_size=128, nlayers=2):\n",
    "    \"Create SimCLR model\"\n",
    "    n_in  = in_channels(encoder)\n",
    "    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))\n",
    "    projector = create_mlp_module(representation.size(1), hidden_size, projection_size, nlayers=2) \n",
    "    apply_init(projector)\n",
    "    return SimCLRModel(encoder, projector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `self_supervised.layers` module to create an encoder. It supports all **timm** and **fastai** models available out of the box.\n",
    "\n",
    "We define number of input channels with `n_in`, projector/mlp's hidden size with `hidden_size`,  projector/mlp's final projection size with `projection_size` and projector/mlp's number of layers with `nlayers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = create_encoder(\"tf_efficientnet_b0_ns\", n_in=3, pretrained=False, pool_type=PoolingType.CatAvgMax)\n",
    "model = create_simclr_model(encoder, hidden_size=2048, projection_size=128, nlayers=2)\n",
    "out = model(torch.randn((2,3,224,224))); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimCLR Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters can be passed;\n",
    "\n",
    "- **size** for random resized cropping\n",
    "- **aug_func** augmentation pipeline function to be used from `self_supervised.augmentations` module\n",
    "- **aug_kwargs** for any keyword arguments to be passed to `aug_func`\n",
    "- **temp** temperature scaling for cross entropy loss (defaults to paper's best value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SimCLR(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, size, aug_func=get_batch_augs, temp=0.07, print_augs=False, **aug_kwargs):\n",
    "        self.aug1 = aug_func(size, **aug_kwargs)\n",
    "        self.aug2 = aug_func(size, **aug_kwargs)\n",
    "        self.temp = temp\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        bs = self.learn.xb[0].shape[0]\n",
    "        self.learn.yb = (torch.arange(bs, device=self.dls.device).roll(bs//2),)\n",
    "    \n",
    "    \n",
    "    def _remove_diag(self, x):\n",
    "        bs = x.shape[0]\n",
    "        return x[~torch.eye(bs).bool()].reshape(bs,bs-1)    \n",
    "    \n",
    "    \n",
    "    def lf(self, pred, *yb):\n",
    "        pred, targ = F.normalize(pred, dim=1), yb[0]\n",
    "        sim = self._remove_diag(pred @ pred.T) / self.temp\n",
    "        targ = self._remove_diag(torch.eye(targ.shape[0], device=self.dls.device)[targ]).nonzero()[:,-1]\n",
    "        return F.cross_entropy(sim, targ)\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def show(self, n=1):\n",
    "        bs = self.learn.x.size(0)//2\n",
    "        x1,x2  = torch.split(self.learn.x, [bs,bs])\n",
    "        idxs = np.random.choice(range(bs),n,False)\n",
    "        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)\n",
    "        images = []\n",
    "        for i in range(n): images += [x1[i],x2[i]] \n",
    "        return show_batch(x1[0], None, images, max_n=n * n, ncols=None, nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DistributedSimCLR` is a distributed implementation of InfoNCE Loss. It effectively increases the number of negative samples to all available samples across all GPUs during loss calculation. For example, if you use batch size of 16 per GPU and 8 GPUs, then the loss will be calculated using a similarity matrix with size of 16x8 x 16x8 = 1024x1024. In literature/experiments it's mentioned that more negatives help training.\n",
    "\n",
    "Following callback should be used together with `DistributedDataParallel` and inside a python script which will be executed in launch mode, such as:\n",
    "\n",
    "> **python -m fastai.launch script.py --FOLD 4 --size 640 --bs 12 --epochs 10 --lr 1e-3 --arch_name tf_efficientnet_b7_ns**\n",
    "\n",
    "For more details about distributed operations like `all gather`, see https://pytorch.org/tutorials/intermediate/dist_tuto.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Training Tip:** You can maximize your effective batchsize by using gradient checkpointing (see self_supervised.layers module), fp16 (to_fp16() in fastai) and distributed callback. Don't worry if you only have access to a single GPU, usually just using gradient checkpointing and fp16 is enough to increase your batch size to 256 and beyond. Which is enough to train highly competitive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from self_supervised.dist import GatherLayer\n",
    "\n",
    "class DistributedSimCLR(Callback):\n",
    "    order,run_valid = 9,True\n",
    "    def __init__(self, size, aug_func=get_batch_augs, temp=0.07, print_augs=False, **aug_kwargs):\n",
    "        self.aug1 = aug_func(size, **aug_kwargs)\n",
    "        self.aug2 = aug_func(size, **aug_kwargs)\n",
    "        self.temp = temp\n",
    "        if print_augs: print(self.aug1), print(self.aug2)\n",
    "        \n",
    "        \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "                    \n",
    "            \n",
    "    def before_batch(self):\n",
    "        xi,xj = self.aug1(self.x), self.aug2(self.x)\n",
    "        self.learn.xb = (torch.cat([xi, xj]),)\n",
    "        bs = self.learn.xb[0].shape[0]\n",
    "        self.learn.yb = (torch.arange(bs, device=self.dls.device).roll(bs//2),)\n",
    "    \n",
    "    \n",
    "    def _remove_diag(self, x):\n",
    "        bs = x.shape[0]\n",
    "        return x[~torch.eye(bs).bool()].reshape(bs,bs-1)    \n",
    "    \n",
    "    \n",
    "    def lf(self, pred, *yb):\n",
    "        # collect all embeddings from other GPUs\n",
    "        all_preds = list(GatherLayer.apply(pred))\n",
    "        # put current rank embeddings to index 0 for loss calc\n",
    "        all_preds.pop(rank_distrib())\n",
    "        all_preds = torch.cat([pred]+all_preds)\n",
    "        \n",
    "        pred, all_preds, targ = F.normalize(pred, dim=1), F.normalize(all_preds, dim=1), yb[0]\n",
    "        sim = self._remove_diag(pred @ all_preds.T) / self.temp\n",
    "        targ = self._remove_diag(torch.eye(targ.shape[0], device=self.dls.device)[targ]).nonzero()[:,-1]\n",
    "        return F.cross_entropy(sim, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=5, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet18, n_in=1, pretrained=False)\n",
    "model = create_simclr_model(fastai_encoder, hidden_size=2048, projection_size=128)\n",
    "learn = Learner(dls, model, cbs=[SimCLR(size=28, aug_func=get_batch_augs,\n",
    "                            rotate=False, jitter=False, bw=False, blur=False,\n",
    "                            stats=None, cuda=False),\n",
    "                     ShortEpochCallback(0.001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, with `show_one()` method you can inspect data augmentations as a sanity check. You can use existing augmentation functions from `augmentations` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x1080 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn('before_batch')\n",
    "axes = learn.sim_clr.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(3.4686)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01 - augmentations.ipynb.\n",
      "Converted 02 - layers.ipynb.\n",
      "Converted 03 - distributed.ipynb.\n",
      "Converted 10 - simclr.ipynb.\n",
      "Converted 11 - moco.ipynb.\n",
      "Converted 12 - byol.ipynb.\n",
      "Converted 13 - swav.ipynb.\n",
      "Converted 20 - clip.ipynb.\n",
      "Converted 21 - clip-moco.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
