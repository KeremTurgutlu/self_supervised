{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq self-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp vision.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision.Metrics\n",
    "\n",
    "> Metrics for tracking performance of self-supervised training. It aims to give an idea about the quality of the learned representations during training in the presence of a labeled validation set. It can be used to decide how much longer to keep training. Since self-supervised models usually favor more epochs it can help save time and computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class KNNProxyMetric(Callback):\n",
    "    \"A metric which calculates knn-1 accuracy. Use with a labeled validation set.\"\n",
    "    order,run_train,run_valid=8,False,True\n",
    "            \n",
    "    def before_batch(self):\n",
    "        self.orig_x, self.orig_y = self.x, self.y\n",
    "    \n",
    "    def before_validate(self):\n",
    "        self.embs = tensor([]).to(self.dls.device)\n",
    "        self.targs = tensor([]).to(self.dls.device)\n",
    "        \n",
    "    def after_pred(self):\n",
    "        self.embs = torch.cat([self.embs, self.model.encoder(self.orig_x)])\n",
    "        self.targs = torch.cat([self.targs, self.orig_y])\n",
    "  \n",
    "    def accuracy(self): \n",
    "        self.embs = F.normalize(self.embs)\n",
    "        sim = self.embs @ self.embs.T\n",
    "        nearest_neighbor = sim.argsort(dim=1, descending=True)[:,1]\n",
    "        return (self.targs == self.targs[nearest_neighbor]).float().mean()\n",
    "        \n",
    "    def after_fit(self):\n",
    "        del self.embs, self.targs\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add a test to check accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_supervised.layers import *\n",
    "from self_supervised.vision.simclr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your dataset as usual. Make sure your validation set has labels. For example, if your dataset has 10% of labeled data and 90% of unlabeled data you can use that 10% or portion of it as your validation set. You assign dummy labels to 90% of data which doesn't have an actual label to circumvent code breaks during dls construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "tds = Datasets(items, [PILImageBW.create, [parent_label, Categorize()]], splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=5, after_item=[ToTensor(), IntToFloatTensor()], device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model and augmentations as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_encoder = create_encoder('xresnet18', n_in=1, pretrained=False)\n",
    "model = create_simclr_model(fastai_encoder, hidden_size=2048, projection_size=128)\n",
    "aug_pipelines = get_simclr_aug_pipelines(size=28, rotate=False, jitter=False, bw=False, blur=False, stats=None, cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define self-supervised alogrithm in cbs. `ShortEpochCallback` is used for testing purposes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip\n",
      "Pipeline: RandomResizedCrop -> RandomHorizontalFlip\n"
     ]
    }
   ],
   "source": [
    "cbs=[SimCLR(aug_pipelines, temp=0.07, print_augs=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `ValueMetric` from fastai since `KNNProxyMetric` is a metric implemented as a Callback. `ValueMetric` expects a function which will return a value when it's called and that function is `KNNProxyMetric.accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_metric_cb = KNNProxyMetric()\n",
    "cbs += [knn_metric_cb]\n",
    "metric = ValueMetric(knn_metric_cb.accuracy, metric_name='knn_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct `Learner` with previously defined `dls`, `cbs` and `metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, cbs=cbs, metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [1.6862106323242188,0.9871244430541992]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01 - augmentations.ipynb.\n",
      "Converted 02 - layers.ipynb.\n",
      "Converted 03 - distributed.ipynb.\n",
      "Converted 10 - simclr.ipynb.\n",
      "Converted 11 - moco.ipynb.\n",
      "Converted 12 - byol.ipynb.\n",
      "Converted 13 - swav.ipynb.\n",
      "Converted 14 - barlow_twins.ipynb.\n",
      "Converted 20 - clip.ipynb.\n",
      "Converted 21 - clip-moco.ipynb.\n",
      "Converted 70 - vision.metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
