{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq self-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multimodal.clip_moco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP-MoCo\n",
    "\n",
    "> CLIP: [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf)\n",
    "\n",
    "> [Official Github Repo](https://github.com/openai/CLIP)\n",
    "\n",
    "> MoCo: [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722.pdf) \n",
    "\n",
    "> MoCo V2: [Improved Baselines with Momentum Contrastive Learning](https://arxiv.org/pdf/2003.04297.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module combines CLIP and MoCo for increasing negative samples. This is useful when there is no available compute such as GPUs with large memory to support large batch sizes or multi-gpu machines to leverage distributed infonce loss implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.augmentations import *\n",
    "from self_supervised.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try:\n",
    "    from clip.simple_tokenizer import SimpleTokenizer\n",
    "except: \n",
    "    raise ImportError(\"\"\"\n",
    "CLIP package is not installed/importable, please visit https://github.com/openai/CLIP or install following:\n",
    "$ pip install ftfy regex tqdm\n",
    "$ pip install git+https://github.com/openai/CLIP.git\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CLIP](images/clip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoCo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/moco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClipTokenizer(DisplayedTransform):\n",
    "    \"Tokenizer from https://github.com/openai/CLIP/blob/main/clip/simple_tokenizer.py\"\n",
    "    def __init__(self, context_length=77):\n",
    "        self._tokenizer = SimpleTokenizer()\n",
    "        self.context_length = context_length\n",
    "        self.vocab_size = len(self._tokenizer.encoder)\n",
    "\n",
    "    def encodes(self:str, text):\n",
    "        sot_token = self._tokenizer.encoder[\"<|startoftext|>\"]\n",
    "        eot_token = self._tokenizer.encoder[\"<|endoftext|>\"]\n",
    "        tokens = [sot_token] + self._tokenizer.encode(text) + [eot_token]\n",
    "        result = torch.zeros(self.context_length, dtype=torch.long)\n",
    "        if len(tokens) > self.context_length: raise Exception(f\"Token length exceeds {self.context_length} for {text}\")            \n",
    "        result[:len(tokens)] = torch.tensor(tokens)\n",
    "        return TensorBase(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def vitb32_config(input_res, context_length, vocab_size):\n",
    "    \"ViT-B/32 configuration, uses 32x32 patches\"\n",
    "    return dict(embed_dim=512,\n",
    "                image_resolution=input_res,\n",
    "                vision_layers=12,\n",
    "                vision_width=768, \n",
    "                vision_patch_size=32,\n",
    "                context_length=context_length, \n",
    "                vocab_size=vocab_size,\n",
    "                transformer_width=512,\n",
    "                transformer_heads=8,\n",
    "                transformer_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def vitl14_config(input_res, context_length, vocab_size):\n",
    "    \"ViT-L/14 configuration, uses 14x14 patches\"\n",
    "    return dict(embed_dim=512,\n",
    "                image_resolution=input_res,\n",
    "                vision_layers=24,\n",
    "                vision_width=1024, \n",
    "                vision_patch_size=14,\n",
    "                context_length=context_length, \n",
    "                vocab_size=vocab_size,\n",
    "                transformer_width=512,\n",
    "                transformer_heads=8,\n",
    "                transformer_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from collections import OrderedDict\n",
    "from typing import Tuple, Union\n",
    "from copy import deepcopy\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # all conv layers have stride 1. an avgpool is performed after the second convolution when stride > 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(stride) if stride > 1 else nn.Identity()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        self.stride = stride\n",
    "\n",
    "        if stride > 1 or inplanes != planes * Bottleneck.expansion:\n",
    "            # downsampling layer is prepended with an avgpool, and the subsequent convolution has stride 1\n",
    "            self.downsample = nn.Sequential(OrderedDict([\n",
    "                (\"-1\", nn.AvgPool2d(stride)),\n",
    "                (\"0\", nn.Conv2d(inplanes, planes * self.expansion, 1, stride=1, bias=False)),\n",
    "                (\"1\", nn.BatchNorm2d(planes * self.expansion))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.avgpool(out)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPool2d(nn.Module):\n",
    "    def __init__(self, spacial_dim: int, embed_dim: int, num_heads: int, output_dim: int = None):\n",
    "        super().__init__()\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(spacial_dim ** 2 + 1, embed_dim) / embed_dim ** 0.5)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.c_proj = nn.Linear(embed_dim, output_dim or embed_dim)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], x.shape[1], x.shape[2] * x.shape[3]).permute(2, 0, 1)  # NCHW -> (HW)NC\n",
    "        x = torch.cat([x.mean(dim=0, keepdim=True), x], dim=0)  # (HW+1)NC\n",
    "        x = x + self.positional_embedding[:, None, :].to(x.dtype)  # (HW+1)NC\n",
    "        x, _ = F.multi_head_attention_forward(\n",
    "            query=x, key=x, value=x,\n",
    "            embed_dim_to_check=x.shape[-1],\n",
    "            num_heads=self.num_heads,\n",
    "            q_proj_weight=self.q_proj.weight,\n",
    "            k_proj_weight=self.k_proj.weight,\n",
    "            v_proj_weight=self.v_proj.weight,\n",
    "            in_proj_weight=None,\n",
    "            in_proj_bias=torch.cat([self.q_proj.bias, self.k_proj.bias, self.v_proj.bias]),\n",
    "            bias_k=None,\n",
    "            bias_v=None,\n",
    "            add_zero_attn=False,\n",
    "            dropout_p=0,\n",
    "            out_proj_weight=self.c_proj.weight,\n",
    "            out_proj_bias=self.c_proj.bias,\n",
    "            use_separate_proj_weight=True,\n",
    "            training=self.training,\n",
    "            need_weights=False\n",
    "        )\n",
    "\n",
    "        return x[0]\n",
    "\n",
    "\n",
    "class ModifiedResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet class that is similar to torchvision's but contains the following changes:\n",
    "    - There are now 3 \"stem\" convolutions as opposed to 1, with an average pool instead of a max pool.\n",
    "    - Performs anti-aliasing strided convolutions, where an avgpool is prepended to convolutions with stride > 1\n",
    "    - The final pooling layer is a QKV attention instead of an average pool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, output_dim, heads, input_resolution=224, width=64):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_resolution = input_resolution\n",
    "\n",
    "        # the 3-layer stem\n",
    "        self.conv1 = nn.Conv2d(3, width // 2, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width // 2)\n",
    "        self.conv2 = nn.Conv2d(width // 2, width // 2, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width // 2)\n",
    "        self.conv3 = nn.Conv2d(width // 2, width, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(width)\n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # residual layers\n",
    "        self._inplanes = width  # this is a *mutable* variable used during construction\n",
    "        self.layer1 = self._make_layer(width, layers[0])\n",
    "        self.layer2 = self._make_layer(width * 2, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(width * 4, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(width * 8, layers[3], stride=2)\n",
    "\n",
    "        embed_dim = width * 32  # the ResNet feature dimension\n",
    "        self.attnpool = AttentionPool2d(input_resolution // 32, embed_dim, heads, output_dim)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        layers = [Bottleneck(self._inplanes, planes, stride)]\n",
    "\n",
    "        self._inplanes = planes * Bottleneck.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Bottleneck(self._inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        def stem(x):\n",
    "            for conv, bn in [(self.conv1, self.bn1), (self.conv2, self.bn2), (self.conv3, self.bn3)]:\n",
    "                x = self.relu(bn(conv(x)))\n",
    "            x = self.avgpool(x)\n",
    "            return x\n",
    "\n",
    "        x = x.type(self.conv1.weight.dtype)\n",
    "        x = stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.attnpool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.LayerNorm):\n",
    "    \"\"\"Subclass torch's LayerNorm to handle fp16.\"\"\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        orig_type = x.dtype\n",
    "        ret = super().forward(x.type(torch.float32))\n",
    "        return ret.type(orig_type)\n",
    "\n",
    "\n",
    "class QuickGELU(nn.Module):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "\n",
    "class ResidualAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int, attn_mask: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_head)\n",
    "        self.ln_1 = LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "            (\"c_fc\", nn.Linear(d_model, d_model * 4)),\n",
    "            (\"gelu\", QuickGELU()),\n",
    "            (\"c_proj\", nn.Linear(d_model * 4, d_model))\n",
    "        ]))\n",
    "        self.ln_2 = LayerNorm(d_model)\n",
    "        self.attn_mask = attn_mask\n",
    "\n",
    "    def attention(self, x: torch.Tensor):\n",
    "        self.attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device) if self.attn_mask is not None else None\n",
    "        return self.attn(x, x, x, need_weights=False, attn_mask=self.attn_mask)[0]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.attention(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, width: int, layers: int, heads: int, attn_mask: torch.Tensor = None, checkpoint=False, checkpoint_nchunks=2):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.resblocks = nn.Sequential(*[ResidualAttentionBlock(width, heads, attn_mask) for _ in range(layers)])\n",
    "        self.checkpoint = checkpoint\n",
    "        self.checkpoint_nchunks = checkpoint_nchunks\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if self.checkpoint: return torch.utils.checkpoint.checkpoint_sequential(self.resblocks, self.checkpoint_nchunks, x)\n",
    "        else:               return self.resblocks(x)\n",
    "\n",
    "\n",
    "class VisualTransformer(nn.Module):\n",
    "    def __init__(self, input_resolution: int, patch_size: int, width: int, layers: int, heads: int, output_dim: int, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.output_dim = output_dim\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=width, kernel_size=patch_size, stride=patch_size, bias=False)\n",
    "\n",
    "        scale = width ** -0.5\n",
    "        self.class_embedding = nn.Parameter(scale * torch.randn(width))\n",
    "        self.positional_embedding = nn.Parameter(scale * torch.randn((input_resolution // patch_size) ** 2 + 1, width))\n",
    "        self.ln_pre = LayerNorm(width)\n",
    "\n",
    "        self.transformer = Transformer(width, layers, heads, **kwargs)\n",
    "\n",
    "        self.ln_post = LayerNorm(width)\n",
    "        self.proj = nn.Parameter(scale * torch.randn(width, output_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)  # shape = [*, width, grid, grid]\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)  # shape = [*, width, grid ** 2]\n",
    "        x = x.permute(0, 2, 1)  # shape = [*, grid ** 2, width]\n",
    "        x = torch.cat([self.class_embedding.to(x.dtype) + torch.zeros(x.shape[0], 1, x.shape[-1], dtype=x.dtype, device=x.device), x], dim=1)  # shape = [*, grid ** 2 + 1, width]\n",
    "        x = x + self.positional_embedding.to(x.dtype)\n",
    "        x = self.ln_pre(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "\n",
    "        x = self.ln_post(x[:, 0, :])\n",
    "\n",
    "        if self.proj is not None:\n",
    "            x = x @ self.proj\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CLIPMOCO(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 # vision\n",
    "                 image_resolution: int,\n",
    "                 vision_layers: Union[Tuple[int, int, int, int], int],\n",
    "                 vision_width: int,\n",
    "                 vision_patch_size: int,\n",
    "                 # text\n",
    "                 context_length: int,\n",
    "                 vocab_size: int,\n",
    "                 transformer_width: int,\n",
    "                 transformer_heads: int,\n",
    "                 transformer_layers: int,\n",
    "                 K=4096,\n",
    "                 m=0.999,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_length = context_length\n",
    "\n",
    "        if isinstance(vision_layers, (tuple, list)):\n",
    "            vision_heads = vision_width * 32 // 64\n",
    "            self.visual = ModifiedResNet(\n",
    "                layers=vision_layers,\n",
    "                output_dim=embed_dim,\n",
    "                heads=vision_heads,\n",
    "                input_resolution=image_resolution,\n",
    "                width=vision_width\n",
    "            )\n",
    "        else:\n",
    "            vision_heads = vision_width // 64\n",
    "            self.visual = VisualTransformer(\n",
    "                input_resolution=image_resolution,\n",
    "                patch_size=vision_patch_size,\n",
    "                width=vision_width,\n",
    "                layers=vision_layers,\n",
    "                heads=vision_heads,\n",
    "                output_dim=embed_dim,\n",
    "                **kwargs\n",
    "            )\n",
    "\n",
    "        self.transformer = Transformer(\n",
    "            width=transformer_width,\n",
    "            layers=transformer_layers,\n",
    "            heads=transformer_heads,\n",
    "            attn_mask=self.build_attention_mask(),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, transformer_width)\n",
    "        self.positional_embedding = nn.Parameter(torch.empty(self.context_length, transformer_width))\n",
    "        self.ln_final = LayerNorm(transformer_width)\n",
    "\n",
    "        self.text_projection = nn.Parameter(torch.empty(transformer_width, embed_dim))\n",
    "        self.logit_scale = nn.Parameter(torch.log(torch.tensor(1/0.07))) # Same initialization as paper\n",
    "\n",
    "        self.initialize_parameters()\n",
    "        \n",
    "        \n",
    "        # MOCO params\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        \n",
    "        # init key encoders\n",
    "        self.visual_key_encoder = deepcopy(self.visual)\n",
    "        for param_k in self.visual_key_encoder.parameters(): param_k.requires_grad = False\n",
    "        self.transformer_key_encoder = deepcopy(self.transformer)\n",
    "        for param_k in self.transformer_key_encoder.parameters(): param_k.requires_grad = False\n",
    "        self.text_projection_key_encoder = deepcopy(self.text_projection)\n",
    "        self.text_projection_key_encoder.requires_grad = False\n",
    "        \n",
    "        # init queues\n",
    "        self.image_queue = torch.randn(self.K, embed_dim)\n",
    "        self.text_queue = torch.randn(self.K, embed_dim)\n",
    "        self.queue_ptr = 0\n",
    "                \n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        nn.init.normal_(self.token_embedding.weight, std=0.02)\n",
    "        nn.init.normal_(self.positional_embedding, std=0.01)\n",
    "        \n",
    "        # visual model\n",
    "        if isinstance(self.visual, ModifiedResNet):\n",
    "            if self.visual.attnpool is not None:\n",
    "                std = self.visual.attnpool.c_proj.in_features ** -0.5\n",
    "                nn.init.normal_(self.visual.attnpool.q_proj.weight, std=std)\n",
    "                nn.init.normal_(self.visual.attnpool.k_proj.weight, std=std)\n",
    "                nn.init.normal_(self.visual.attnpool.v_proj.weight, std=std)\n",
    "                nn.init.normal_(self.visual.attnpool.c_proj.weight, std=std)\n",
    "\n",
    "            for resnet_block in [self.visual.layer1, self.visual.layer2, self.visual.layer3, self.visual.layer4]:\n",
    "                for name, param in resnet_block.named_parameters():\n",
    "                    if name.endswith(\"bn3.weight\"):\n",
    "                        nn.init.zeros_(param)\n",
    "        \n",
    "        # text model\n",
    "        proj_std = (self.transformer.width ** -0.5) * ((2 * self.transformer.layers) ** -0.5)\n",
    "        attn_std = self.transformer.width ** -0.5\n",
    "        fc_std = (2 * self.transformer.width) ** -0.5\n",
    "        for block in self.transformer.resblocks:\n",
    "            nn.init.normal_(block.attn.in_proj_weight, std=attn_std)\n",
    "            nn.init.normal_(block.attn.out_proj.weight, std=proj_std)\n",
    "            nn.init.normal_(block.mlp.c_fc.weight, std=fc_std)\n",
    "            nn.init.normal_(block.mlp.c_proj.weight, std=proj_std)\n",
    "\n",
    "        if self.text_projection is not None:\n",
    "            nn.init.normal_(self.text_projection, std=self.transformer.width ** -0.5)\n",
    "\n",
    "    def build_attention_mask(self):\n",
    "        # lazily create causal attention mask, with full attention between the vision tokens\n",
    "        # pytorch uses additive attention mask; fill with -inf\n",
    "        mask = torch.empty(self.context_length, self.context_length)\n",
    "        mask.fill_(float(\"-inf\"))\n",
    "        mask.triu_(1)  # zero out the lower diagonal\n",
    "        return mask\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.conv1.weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = x + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection\n",
    "        return x\n",
    "    \n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoders(self):\n",
    "        for param_q, param_k in zip(self.visual.parameters(), self.visual_key_encoder.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "            \n",
    "        for param_q, param_k in zip(self.transformer.parameters(), self.transformer_key_encoder.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "    \n",
    "        self.text_projection_key_encoder.data = self.text_projection_key_encoder.data * self.m + self.text_projection.data * (1. - self.m)\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, image_k, text_k):\n",
    "        bs = image_k.size(0)\n",
    "        assert self.K % bs == 0  # for simplicity\n",
    "        self.image_queue[self.queue_ptr:self.queue_ptr+bs, :] = image_k\n",
    "        self.text_queue[self.queue_ptr:self.queue_ptr+bs, :] = text_k\n",
    "        self.queue_ptr = (self.queue_ptr + bs) % self.K  # move pointer\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def key_encode_image(self, image):\n",
    "        return self.visual_key_encoder(image.type(self.dtype))\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def key_encode_text(self, text):\n",
    "        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = x + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer_key_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection_key_encoder\n",
    "        return x\n",
    "        \n",
    "\n",
    "    def forward(self, image, text):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(text)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        return image_features, text_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful proxy metric for tracking training performance and convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RetrievalAtK(AccumMetric):\n",
    "    \n",
    "    def __init__(self, k=20, **kwargs):\n",
    "        super().__init__(func=None, flatten=False, **kwargs)\n",
    "        self.k = k\n",
    "        \n",
    "    @property\n",
    "    def value(self):\n",
    "        \"For monitoring retrieval at k during training for sanity checking, should be used on < ~10000 samples\"\n",
    "        if len(self.preds) == 0: return\n",
    "        \n",
    "        image_features = torch.cat(list(L(self.preds).itemgot(0)))\n",
    "        text_features = torch.cat(list(L(self.preds).itemgot(1)))\n",
    "        ranking = torch.argsort(to_detach(image_features.to(default_device()) @ text_features.T.to(default_device()), gather=False), \n",
    "                                descending=True)        \n",
    "        preds = array(torch.where(ranking == torch.arange(len(image_features)).view(-1,1))[1])\n",
    "        \n",
    "        if self.k == \"mean\":     return preds.mean() + 1\n",
    "        elif self.k == \"median\": return np.floor(np.median(preds)) + 1\n",
    "        else:                    return np.mean(preds < self.k)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def name(self):  \n",
    "        if self.k == \"mean\":     return \"mean_retrieval_ranking\"\n",
    "        elif self.k == \"median\": return \"median_retrieval_ranking\"\n",
    "        else:                    return f\"retrieval_at_{self.k}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP-MoCo Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CLIPMOCOTrainer(Callback):\n",
    "    \"MoCo Loss for CLIP. Can be used with or without DistributedDataParallel\"\n",
    "    order,run_valid = 9,True\n",
    "    \n",
    "    def before_fit(self): \n",
    "        self.learn.loss_func = self.lf\n",
    "        \n",
    "    def before_batch(self):\n",
    "        \"Generate image and text key for the current batch\"\n",
    "        with torch.no_grad():\n",
    "            img_b, text_b = self.learn.xb\n",
    "            key_image_features = self.learn.model.key_encode_image(img_b)\n",
    "            key_text_features = self.learn.model.key_encode_text(text_b)\n",
    "            key_image_features = key_image_features / key_image_features.norm(dim=-1, keepdim=True)\n",
    "            key_text_features = key_text_features / key_text_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "        self.learn.yb = (key_image_features, key_text_features)\n",
    "        \n",
    "    \n",
    "    def lf(self, pred, *yb): \n",
    "        key_image_features, key_text_features = yb\n",
    "        image_features, text_features = pred\n",
    "        logit_scale = self.model.logit_scale.exp()\n",
    "        \n",
    "        logits_per_image = logit_scale * image_features @ key_text_features.t()\n",
    "        logits_per_text = logit_scale * text_features @ key_image_features.t()\n",
    "\n",
    "        labels = torch.arange(len(logits_per_image)).to(logits_per_image.device)\n",
    "        image_loss = F.cross_entropy(logits_per_image, labels)\n",
    "        text_loss  = F.cross_entropy(logits_per_text, labels)\n",
    "        return (image_loss+text_loss)/2\n",
    "    \n",
    "    \n",
    "    \n",
    "    def after_step(self):\n",
    "        # logit scaling set as max 100\n",
    "        if num_distrib()==0: self.model.logit_scale.data = torch.clamp(self.model.logit_scale.data, 0, 4.6052) \n",
    "        else:               self.model.module.logit_scale.data = torch.clamp(self.model.module.logit_scale.data, 0, 4.6052) \n",
    "        \n",
    "        # queues update\n",
    "        key_image_features, key_text_features = self.learn.yb\n",
    "        self.learn.model._dequeue_and_enqueue(key_image_features, key_text_features)\n",
    "        \n",
    "        # momentum update\n",
    "        self.learn.model._momentum_update_key_encoders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2txt = {'3': 'three', '7': 'seven'}\n",
    "def num_to_txt(o): return num2txt[o]\n",
    "def dummy_targ(o): return 0 # loss func is not called without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)\n",
    "clip_tokenizer = ClipTokenizer()\n",
    "tds = Datasets(items, [PILImage.create, [parent_label, num_to_txt], dummy_targ], n_inp=2, splits=GrandparentSplitter()(items))\n",
    "dls = tds.dataloaders(bs=2, after_item=[Resize(224), clip_tokenizer, ToTensor()], after_batch=[IntToFloatTensor()], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitb32_config_dict = vitb32_config(224, clip_tokenizer.context_length, clip_tokenizer.vocab_size)\n",
    "clip_model = CLIPMOCO(K=4096,m=0.999, **vitb32_config_dict, checkpoint=False, checkpoint_nchunks=0)\n",
    "learner = Learner(dls, clip_model, loss_func=noop, cbs=[CLIPMOCOTrainer(), ShortEpochCallback(0.001)],\n",
    "                  metrics=[RetrievalAtK(k=5), \n",
    "                           RetrievalAtK(k=20), \n",
    "                           RetrievalAtK(k=\"mean\"),\n",
    "                           RetrievalAtK(k=\"median\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CLIPMOCO (Input shape: 2 x torch.Size([2, 77]))\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 768 x 7 x 7     \n",
       "Conv2d                                    2359296    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1536       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    True      \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 77 x 512        \n",
       "Embedding                                 25296896   True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 768 x 7 x 7     \n",
       "Conv2d                                    2359296    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 3072        \n",
       "Linear                                    2362368    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 768         \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1536       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 2048        \n",
       "Linear                                    1050624    False     \n",
       "QuickGELU                                                      \n",
       "____________________________________________________________________________\n",
       "                     2 x 1 x 512         \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 193,876,992\n",
       "Total trainable params: 109,587,456\n",
       "Total non-trainable params: 84,289,536\n",
       "\n",
       "Optimizer used: <function Adam at 0x7fbd8d0189e0>\n",
       "Loss function: <bound method CLIPMOCOTrainer.lf of CLIPMOCOTrainer>\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - ShortEpochCallback\n",
       "  - CLIPMOCOTrainer\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Causes kernel died error in CI - github actions\n",
    "# learner.fit(1)\n",
    "# learner.recorder.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
