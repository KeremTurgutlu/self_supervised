{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "> Utility functions to help with downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from self_supervised.byol import *\n",
    "from self_supervised.simclr import *\n",
    "from self_supervised.swav import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Weights for Downstream Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def transfer_weights(learn:Learner, weights_path:Path, device:torch.device=None):\n",
    "    \"Load and freeze pretrained weights inplace from `weights_path` using `device`\"\n",
    "    if device is None: device = learn.dls.device\n",
    "    new_state_dict = torch.load(weights_path, map_location=device)\n",
    "    if 'model' in new_state_dict.keys(): new_state_dict = new_state_dict['model'] \n",
    "    #allow for simply exporting the raw PyTorch model\n",
    "    learn_state_dict = learn.model.state_dict()\n",
    "    matched_layers = 0\n",
    "    for name, param in learn_state_dict.items():\n",
    "        name = 'encoder.'+name[2:]\n",
    "        if name in new_state_dict:\n",
    "            matched_layers += 1\n",
    "            input_param = new_state_dict[name]\n",
    "            if input_param.shape == param.shape:\n",
    "                param.copy_(input_param)\n",
    "            else:\n",
    "                raise ValueError(f'Shape mismatch at {name}, please ensure you have the same backbone')\n",
    "        else: pass # these are weights that weren't in the original model, such as a new head\n",
    "    if matched_layers == 0: raise Exception(\"No shared weight names were found between the models\")\n",
    "    learn.model.load_state_dict(learn_state_dict)\n",
    "    learn.freeze()\n",
    "    print(\"Weights successfully transferred!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training models with this library, the `state_dict` will change, so loading it back into `fastai` as an encoder won't be a perfect match. This helper function aims to make that simple. \n",
    "\n",
    "Example usage:\n",
    "\n",
    "First prepare the downstream-task dataset (`ImageWoof` is shown here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGEWOOF)\n",
    "tfms = [[PILImage.create], [parent_label, Categorize()]]\n",
    "item_tfms = [ToTensor(), Resize(224)]\n",
    "batch_tfms = [FlipItem(), RandomResizedCrop(224, min_scale=0.35),\n",
    "          IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)]\n",
    "items = get_image_files(path)\n",
    "splits = GrandparentSplitter(valid_name='val')(items)\n",
    "dsets = Datasets(items, tfms, splits=splits)\n",
    "dls = dsets.dataloaders(after_item=item_tfms, after_batch=batch_tfms,\n",
    "                      bs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of example we will make and save a SWaV model trained for one epoch (in reality you'd want to train for many more):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_swav_model(arch=xresnet50, pretrained=False)\n",
    "learn = Learner(dls, net, SWAVLoss(), cbs=[SWAV()])\n",
    "learn.save('../../../swav_test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed by a `Learner` designed for classification with a simple custom head for our `xresnet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = create_body(xresnet34, pretrained=False)\n",
    "nf = num_features_model(body)*2\n",
    "head = create_head(nf, dls.c)\n",
    "arch = nn.Sequential(body, head)\n",
    "\n",
    "learn = Learner(dls, arch, splitter=default_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading in all the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights successfully transferred!\n"
     ]
    }
   ],
   "source": [
    "transfer_weights(learn, '../../swav_test.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do downstream tasks with our pretrained models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
