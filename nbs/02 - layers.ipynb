{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq self-supervised  # upgrade self-supervised on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Utilities for creating torch Modules for self supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://github.com/rwightman/pytorch-image-models/blob/3a7aa95f7e5fc90a6a2683c756e854e26201d82e/timm/models/layers/adaptive_avgmax_pool.py#L79\n",
    "mk_class('PoolingType', **{o:o.lower() for o in ['Fast', 'Avg', 'AvgMax', 'CatAvgMax', 'Max']},\n",
    "         doc=\"All possible pooling types as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['PoolingType', '_splitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_fastai_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Create timm encoder from a given arch backbone\"\n",
    "    encoder = create_body(arch, n_in, pretrained, cut=None)\n",
    "    pool = AdaptiveConcatPool2d() if pool_type == \"catavgmax\" else nn.AdaptiveAvgPool2d(1)\n",
    "    return nn.Sequential(*encoder, pool, Flatten())\n",
    "\n",
    "def create_timm_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Creates a body from any model in the `timm` library. If pool_type is None then it uses timm default\"\n",
    "    if ('vit' in arch) or (pool_type is None):\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0)\n",
    "    else:\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0, global_pool=pool_type)\n",
    "    return model\n",
    "\n",
    "def create_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"A utility for creating encoder without specifying the package\"\n",
    "    if arch in globals(): return create_fastai_encoder(globals()[arch], pretrained, n_in, pool_type)\n",
    "    else:                 return create_timm_encoder(arch, pretrained, n_in, pool_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((1,3,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai encoder expects a function as it's first argument, where timm expects a string. Also, fastai defaults to concat pooling, aka `catavgmax` in timm. With timm's selective pooling any `PoolingType` can used. Experiments show that concat pooling is better on average so it is set as our default.\n",
    "\n",
    "For any other `pool_type` fastai uses `AdaptiveAvgPool2d`, for timm you can choose from the remaining `PoolingType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34, pool_type=False)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"xresnet34\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision Transformer is a special case which uses `Layernorm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model = create_timm_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = vit_model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mlp_module(dim,hidden_size,projection_size,bn=False,nlayers=2):\n",
    "    \"MLP module as described in papers, used as projection layer\"\n",
    "    l = []\n",
    "    for i in range(nlayers-1):\n",
    "        l += [nn.Linear(dim, hidden_size) if i == 0 else nn.Linear(hidden_size, hidden_size)] \n",
    "        if bn: l += [nn.BatchNorm1d(hidden_size)]\n",
    "        l += [nn.ReLU(inplace=True)]\n",
    "    ls = l + [nn.Linear(hidden_size, projection_size)]\n",
    "    return nn.Sequential(*ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR\n",
    "create_mlp_module(1024,4096,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR-v2\n",
    "create_mlp_module(1024,4096,128,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BYOL\n",
    "create_mlp_module(1024,4096,128,bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SWAV\n",
    "create_mlp_module(1024,4096,128,bn=True,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_cls_module(nf, n_out, lin_ftrs=None, ps=0.5, use_bn=True, first_bn=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Creates classification layer which takes nf flatten features and outputs n_out logits\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [use_bn]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((2,3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"xresnet34\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5934,  0.0218, -1.0546, -0.0870, -0.0212],\n",
      "        [ 0.8928,  1.1403,  0.0279, -0.5045, -1.0595]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0023, -0.0434, -0.1689,  0.7236,  1.4304],\n",
      "        [ 0.2860,  0.3319, -1.1037, -0.1302, -1.2017]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_model` can be used to create models for classification, for example quickly creating a model for downstream classification training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(create_cls_module)\n",
    "def create_model(arch, n_out, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax, **kwargs):\n",
    "    encoder = create_encoder(arch, pretrained=pretrained, n_in=n_in, pool_type=pool_type)\n",
    "    sz = int(arch.split(\"_\")[-1]) if 'vit'in arch else 224\n",
    "    with torch.no_grad(): nf = encoder(torch.randn(2,3,sz,sz)).size(-1)\n",
    "    head = create_cls_module(nf, n_out, **kwargs)\n",
    "    apply_init(head)\n",
    "    model = nn.Sequential(encoder, head)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_splitter` can be passed to `Learner(...,splitter=splitter_func)`. This can be used to freeze or unfreeze encoder layers, in this case first parameter group is the encoder and second parameter group is the classification head. Simply by indexing to model[0] and model[1] we can access encoder and classification head modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _splitter(m): return L(m[0], m[1]).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25, inplace=False)\n",
       "  (2): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=512, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"xresnet34\", 10, pretrained=False)\n",
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6586,  2.8627,  0.5942,  1.3333, -0.7247, -0.1750,  0.4790, -4.1426,\n",
      "          0.3254,  0.5920],\n",
      "        [-0.6557,  0.3469, -3.1064,  0.4271,  3.6438,  0.0830, -1.9096,  4.2991,\n",
      "         -1.3772,  0.3817]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.25, inplace=False)\n",
       "  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"vit_large_patch16_384\", 10, pretrained=False, use_bn=False, first_bn=False, bn_final=False)\n",
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2183,  2.0234, -4.9572, -1.5017,  5.2824, -0.1557,  1.8053,  2.5815,\n",
      "          1.0612,  1.0911],\n",
      "        [ 0.8053, -0.1254, -1.0162, -2.4544,  3.7484,  0.2554,  1.4608,  0.5014,\n",
      "         -1.6777, -2.0474]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Checkpointing\n",
    "\n",
    "For memory conservation, to train with larger image resolution and/or batch size. For now it's compatible with **timm** EfficientNet and ResNet models, and **fastai** models. But it should be easy to implement for any encoder model that you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a current fix for using gradient checkpointing with autocast / `to_fp16()` https://github.com/pytorch/pytorch/pull/49757/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "\n",
    "class CheckpointResNet(Module):\n",
    "    def __init__(self, resnet_model, checkpoint_nchunks=2):\n",
    "        \"Up to 4 chunks\"\n",
    "        self.checkpoint_nchunks = checkpoint_nchunks\n",
    "        self.resnet_model = resnet_model\n",
    "        self.forward_layers = nn.Sequential(*[\n",
    "            self.resnet_model.layer1,\n",
    "            self.resnet_model.layer2,\n",
    "            self.resnet_model.layer3,\n",
    "            self.resnet_model.layer4\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet_model.conv1(x)\n",
    "        x = self.resnet_model.bn1(x)\n",
    "        x = self.resnet_model.act1(x)\n",
    "        x = self.resnet_model.maxpool(x)\n",
    "            \n",
    "        x = checkpoint_sequential(self.forward_layers, self.checkpoint_nchunks, x)\n",
    "        x = self.resnet_model.global_pool(x)\n",
    "        \n",
    "        if self.resnet_model.drop_rate:\n",
    "            x = F.dropout(x, p=float(self.resnet_model.drop_rate), training=self.resnet_model.training)\n",
    "        x = self.resnet_model.fc(x)\n",
    "        return x\n",
    "\n",
    "class CheckpointEfficientNet(Module):\n",
    "    def __init__(self, effnet_model, checkpoint_nchunks=2):\n",
    "        self.checkpoint_nchunks = checkpoint_nchunks\n",
    "        self.effnet_model = effnet_model\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        x = self.effnet_model.conv_stem(x)\n",
    "        x = self.effnet_model.bn1(x)\n",
    "        x = self.effnet_model.act1(x)\n",
    "        x = checkpoint_sequential(self.effnet_model.blocks, self.checkpoint_nchunks, x)\n",
    "        x = self.effnet_model.conv_head(x)\n",
    "        x = self.effnet_model.bn2(x)\n",
    "        x = self.effnet_model.act2(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.effnet_model.global_pool(x)\n",
    "        if self.effnet_model.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.effnet_model.drop_rate, training=self.effnet_model.training)\n",
    "        return self.effnet_model.classifier(x)\n",
    "\n",
    "class CheckpointSequential(Module):\n",
    "    def __init__(self, fastai_model, checkpoint_nchunks=2):\n",
    "        \"This can be used for checkpointing fastai encoders which are sequential models\"\n",
    "        self.checkpoint_nchunks = checkpoint_nchunks\n",
    "        self.fastai_model = fastai_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = checkpoint_sequential(self.fastai_model, self.checkpoint_nchunks, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['seresnet50','seresnet50tn','skresnet50','skresnet50d','ssl_resnet50','swsl_resnet50','tv_resnet50','vit_base_resnet50d_224','vit_small_resnet50d_s3_224','wide_resnet50_2']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(timm.list_models(\"*resnet50*\"))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2153, -0.8222, -0.1195, -0.1419,  0.2558],\n",
      "        [-0.0267,  1.1275,  0.4353, -0.2715, -1.3025]])\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(\"seresnet50\", pretrained=False)\n",
    "encoder = CheckpointResNet(encoder, checkpoint_nchunks=4)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)\n",
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['tf_efficientnet_el','tf_efficientnet_em','tf_efficientnet_es','tf_efficientnet_l2_ns','tf_efficientnet_l2_ns_475','tf_efficientnet_lite0','tf_efficientnet_lite1','tf_efficientnet_lite2','tf_efficientnet_lite3','tf_efficientnet_lite4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(timm.list_models(\"*efficientnet*\"))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2183, -1.7747,  0.6225, -0.2091, -0.6604],\n",
      "        [-0.4133,  1.4024,  0.4160, -0.6159,  0.6558]])\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(\"tf_efficientnet_b0_ns\", pretrained=False)\n",
    "encoder = CheckpointEfficientNet(encoder, checkpoint_nchunks=4)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)\n",
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2094, -0.0202,  1.5631,  0.8257,  0.8442],\n",
      "        [-0.4477, -0.2046, -0.9960, -1.3508,  0.2298]])\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(\"xresnet34\", pretrained=False)\n",
    "encoder = CheckpointSequential(encoder, checkpoint_nchunks=4)\n",
    "out = encoder(inp)\n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)\n",
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01 - augmentations.ipynb.\n",
      "Converted 02 - layers.ipynb.\n",
      "Converted 03 - distributed.ipynb.\n",
      "Converted 10 - simclr.ipynb.\n",
      "Converted 11 - moco.ipynb.\n",
      "Converted 12 - byol.ipynb.\n",
      "Converted 13 - swav.ipynb.\n",
      "Converted 20 - clip.ipynb.\n",
      "Converted 21 - clip-moco.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
