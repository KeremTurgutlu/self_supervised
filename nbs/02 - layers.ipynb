{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Utilities for creating torch Modules for self supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://github.com/rwightman/pytorch-image-models/blob/3a7aa95f7e5fc90a6a2683c756e854e26201d82e/timm/models/layers/adaptive_avgmax_pool.py#L79\n",
    "mk_class('PoolingType', **{o:o.lower() for o in ['Fast', 'Avg', 'AvgMax', 'CatAvgMax', 'Max']},\n",
    "         doc=\"All possible pooling types as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['PoolingType', '_splitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_fastai_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Create timm encoder from a given arch backbone\"\n",
    "    encoder = create_body(arch, n_in, pretrained, cut=None)\n",
    "    pool = AdaptiveConcatPool2d() if pool_type == \"catavgmax\" else nn.AdaptiveAvgPool2d(1)\n",
    "    return nn.Sequential(*encoder, pool, Flatten())\n",
    "\n",
    "def create_timm_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"Creates a body from any model in the `timm` library. If pool_type is None then it uses timm default\"\n",
    "    if ('vit' in arch) or (pool_type is None):\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0)\n",
    "    else:\n",
    "        model = timm.create_model(arch, pretrained=pretrained, in_chans=n_in, num_classes=0, global_pool=pool_type)\n",
    "    return model\n",
    "\n",
    "def create_encoder(arch:str, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax):\n",
    "    \"A utility for creating encoder without specifying the package\"\n",
    "    if arch in globals(): return create_fastai_encoder(globals()[arch], pretrained, n_in, pool_type)\n",
    "    else:                 return create_timm_encoder(arch, pretrained, n_in, pool_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((1,3,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai encoder expects a function as it's first argument, where timm expects a string. Also, fastai defaults to concat pooling, aka `catavgmax` in timm. With timm's selective pooling any `PoolingType` can used. Experiments show that concat pooling is better on average so it is set as our default.\n",
    "\n",
    "For any other `pool_type` fastai uses `AdaptiveAvgPool2d`, for timm you can choose from the remaining `PoolingType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_encoder = create_fastai_encoder(xresnet34, pool_type=False)\n",
    "out = fastai_encoder(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_timm_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"xresnet34\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_encoder(\"tf_efficientnet_b0_ns\", pretrained=False, pool_type=PoolingType.Avg)\n",
    "out = model(inp); out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision Transformer is a special case which uses `Layernorm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model = create_timm_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = vit_model(inp); out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mlp_module(dim,hidden_size,projection_size,bn=False,nlayers=2):\n",
    "    \"MLP module as described in papers, used as projection layer\"\n",
    "    l = []\n",
    "    for i in range(nlayers-1):\n",
    "        l += [nn.Linear(dim, hidden_size) if i == 0 else nn.Linear(hidden_size, hidden_size)] \n",
    "        if bn: l += [nn.BatchNorm1d(hidden_size)]\n",
    "        l += [nn.ReLU(inplace=True)]\n",
    "    ls = l + [nn.Linear(hidden_size, projection_size)]\n",
    "    return nn.Sequential(*ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR\n",
    "create_mlp_module(1024,4096,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SimCLR-v2\n",
    "create_mlp_module(1024,4096,128,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BYOL\n",
    "create_mlp_module(1024,4096,128,bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SWAV\n",
    "create_mlp_module(1024,4096,128,bn=True,nlayers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_cls_module(nf, n_out, lin_ftrs=None, ps=0.5, use_bn=True, first_bn=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Creates classification layer which takes nf flatten features and outputs n_out logits\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [use_bn]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((2,3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"xresnet34\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4578,  0.1962,  0.3483,  0.2693,  0.4036],\n",
      "        [ 0.9672,  0.4732, -0.2438,  0.0639,  0.4530]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(\"vit_large_patch16_384\", pretrained=False)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2020,  0.5703, -0.5863, -0.5270, -0.2258],\n",
      "        [-0.1256,  0.6353,  0.2566,  0.1461, -1.0126]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_model` can be used to create models for classification, for example quickly creating a model for downstream classification training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(create_cls_module)\n",
    "def create_model(arch, n_out, pretrained=True, n_in=3, pool_type=PoolingType.CatAvgMax, **kwargs):\n",
    "    encoder = create_encoder(arch, pretrained=pretrained, n_in=n_in, pool_type=pool_type)\n",
    "    sz = int(arch.split(\"_\")[-1]) if 'vit'in arch else 224\n",
    "    with torch.no_grad(): nf = encoder(torch.randn(2,3,sz,sz)).size(-1)\n",
    "    head = create_cls_module(nf, n_out, **kwargs)\n",
    "    apply_init(head)\n",
    "    model = nn.Sequential(encoder, head)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_splitter` can be passed to `Learner(...,splitter=splitter_func)`. This can be used to freeze or unfreeze encoder layers, in this case first parameter group is the encoder and second parameter group is the classification head. Simply by indexing to model[0] and model[1] we can access encoder and classification head modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _splitter(m): return L(m[0], m[1]).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25, inplace=False)\n",
       "  (2): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=512, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"xresnet34\", 10, pretrained=False)\n",
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9801,  0.5984,  1.0496,  0.1027, -0.9296,  0.3743,  0.2912, -2.2145,\n",
      "          0.9631,  0.6881],\n",
      "        [-3.6033,  3.1260, -2.1505, -3.1446, -3.0479,  1.5577,  0.2835,  1.5043,\n",
      "          0.7752, -3.0250]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.25, inplace=False)\n",
       "  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(\"vit_large_patch16_384\", 10, pretrained=False, use_bn=False, first_bn=False, bn_final=False)\n",
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1885,  2.5996,  0.4422, -2.1230, -0.4676, -3.3507, -1.7186,  0.6813,\n",
      "          2.8931, -2.0293],\n",
      "        [-2.0357,  1.7495, -1.6751, -0.9574,  2.8662,  0.9931,  0.8798, -0.3587,\n",
      "         -0.7292,  1.7749]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Checkpointing\n",
    "\n",
    "For memory conservation, to train with larger image resolution and/or batch size. For now it's compatible with timm EfficientNet and ResNet models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/pytorch/pull/49757/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "\n",
    "class CheckpointResNet(Module):\n",
    "    def __init__(self, resnet_model, checkpoint_nchunks=2):\n",
    "        \"Up to 4 chunks\"\n",
    "        self.checkpoint_nchunks = checkpoint_nchunks\n",
    "        self.resnet_model = resnet_model\n",
    "        self.forward_layers = nn.Sequential(*[\n",
    "            self.resnet_model.layer1,\n",
    "            self.resnet_model.layer2,\n",
    "            self.resnet_model.layer3,\n",
    "            self.resnet_model.layer4\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet_model.conv1(x)\n",
    "        x = self.resnet_model.bn1(x)\n",
    "        x = self.resnet_model.act1(x)\n",
    "        x = self.resnet_model.maxpool(x)\n",
    "            \n",
    "        x = checkpoint_sequential(self.forward_layers, self.checkpoint_nchunks, x)\n",
    "        x = self.resnet_model.global_pool(x)\n",
    "        \n",
    "        if self.resnet_model.drop_rate:\n",
    "            x = F.dropout(x, p=float(self.resnet_model.drop_rate), training=self.resnet_model.training)\n",
    "        x = self.resnet_model.fc(x)\n",
    "        return x\n",
    "\n",
    "class CheckpointEfficientNet(Module):\n",
    "    def __init__(self, effnet_model, checkpoint_nchunks=2):\n",
    "        self.checkpoint_nchunks = checkpoint_nchunks\n",
    "        self.effnet_model = effnet_model\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        x = self.effnet_model.conv_stem(x)\n",
    "        x = self.effnet_model.bn1(x)\n",
    "        x = self.effnet_model.act1(x)\n",
    "        x = checkpoint_sequential(self.effnet_model.blocks, self.checkpoint_nchunks, x)\n",
    "        x = self.effnet_model.conv_head(x)\n",
    "        x = self.effnet_model.bn2(x)\n",
    "        x = self.effnet_model.act2(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.effnet_model.global_pool(x)\n",
    "        if self.effnet_model.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.effnet_model.drop_rate, training=self.effnet_model.training)\n",
    "        return self.effnet_model.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['seresnet50','seresnet50tn','skresnet50','skresnet50d','ssl_resnet50','swsl_resnet50','tv_resnet50','vit_base_resnet50d_224','vit_small_resnet50d_s3_224','wide_resnet50_2']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(timm.list_models(\"*resnet50*\"))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7324, -1.0348,  0.5049,  1.4302,  0.4787],\n",
      "        [-0.4420,  1.2445,  0.4338, -0.2882, -0.3465]])\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(\"seresnet50\", pretrained=False)\n",
    "encoder = CheckpointResNet(encoder, checkpoint_nchunks=4)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)\n",
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['tf_efficientnet_el','tf_efficientnet_em','tf_efficientnet_es','tf_efficientnet_l2_ns','tf_efficientnet_l2_ns_475','tf_efficientnet_lite0','tf_efficientnet_lite1','tf_efficientnet_lite2','tf_efficientnet_lite3','tf_efficientnet_lite4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(timm.list_models(\"*efficientnet*\"))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2597,  0.4224, -0.0271,  0.3732, -0.2489],\n",
      "        [ 1.0614, -0.0026, -0.8835, -0.2534,  0.0913]])\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(\"tf_efficientnet_b0_ns\", pretrained=False)\n",
    "encoder = CheckpointEfficientNet(encoder, checkpoint_nchunks=4)\n",
    "out = encoder(inp) \n",
    "classifier = create_cls_module(out.size(-1), n_out=5, first_bn=False)\n",
    "model = nn.Sequential(encoder, classifier)\n",
    "with torch.no_grad(): print(model(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01-augmentations.ipynb.\n",
      "Converted 02-layers.ipynb.\n",
      "Converted 03-distributed.ipynb.\n",
      "Converted 10-simclr.ipynb.\n",
      "Converted 11-byol.ipynb.\n",
      "Converted 12-swav.ipynb.\n",
      "Converted 13-moco.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
