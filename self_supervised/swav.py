# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/30-swav.ipynb (unless otherwise specified).

__all__ = ['get_aug_pipe', 'create_encoder', 'MLP', 'SwAVModel', 'create_swav_model', 'distributed_sinkhorn', 'SwAV']

# Cell
from fastai.vision.all import *
import kornia

# Cell
def get_aug_pipe(size, min_scale=0.2, max_scale=1., stats=imagenet_stats, s=.6,
                 color=True, xtra_tfms=[]):
    "SimCLR augmentations"
    tfms = []
    tfms += [kornia.augmentation.RandomResizedCrop((size, size),
                                                   scale=(min_scale, max_scale),
                                                   ratio=(3/4, 4/3))]
    tfms += [kornia.augmentation.RandomHorizontalFlip()]

    if color: tfms += [kornia.augmentation.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)]
    if color: tfms += [kornia.augmentation.RandomGrayscale(p=0.2)]
    if stats is not None: tfms += [Normalize.from_stats(*stats)]

    tfms += xtra_tfms

    pipe = Pipeline(tfms)
    pipe.split_idx = 0
    return pipe

# Cell
def create_encoder(arch, n_in=3, pretrained=True, cut=None, concat_pool=True):
    "Create encoder from a given arch backbone"
    encoder = create_body(arch, n_in, pretrained, cut)
    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)
    return nn.Sequential(*encoder, pool, Flatten())

# Cell
class MLP(Module):
    "MLP module as described in paper"
    def __init__(self, dim, projection_size=256, hidden_size=2048):
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_size, projection_size)
        )

    def forward(self, x):
        return self.net(x)

# Cell
class SwAVModel(Module):
    def __init__(self,encoder,projector,prototypes):
        self.encoder,self.projector,self.prototypes = encoder,projector,prototypes

    def forward(self, inputs):

        if not isinstance(inputs, list): inputs = [inputs]

        crop_idxs = torch.cumsum(torch.unique_consecutive(
                                torch.tensor([inp.shape[-1] for inp in inputs]),
                                return_counts=True)[1], 0)

        start_idx = 0
        for idx in crop_idxs:
            _z = self.encoder(torch.cat(inputs[start_idx: idx]))
            if not start_idx: z = _z
            else:             z = torch.cat((z, _z))
            start_idx = idx

        z = F.normalize(self.projector(z))
        return z, self.prototypes(z)

# Cell
def create_swav_model(arch=resnet50, n_in=3, pretrained=True, cut=None, concat_pool=True,
                      hidden_size=256, projection_size=128, n_protos=3000):
    "Create SwAV from a given arch"
    encoder = create_encoder(arch, n_in, pretrained, cut, concat_pool)
    with torch.no_grad(): representation = encoder(torch.randn((2,n_in,128,128)))
    projector = MLP(representation.size(1), projection_size, hidden_size=hidden_size)
    prototypes = nn.Linear(projection_size, n_protos, bias=False)
    apply_init(projector)
    apply_init(prototypes)
    return SwAVModel(encoder, projector, prototypes)

# Cell
def distributed_sinkhorn(Q, nmb_iters):
    with torch.no_grad():
        sum_Q = torch.sum(Q)
        dist.all_reduce(sum_Q)
        Q /= sum_Q

        r = torch.ones(Q.shape[0]).cuda(non_blocking=True) / Q.shape[0]
        c = torch.ones(Q.shape[1]).cuda(non_blocking=True) / (args.world_size * Q.shape[1])

        curr_sum = torch.sum(Q, dim=1)
        dist.all_reduce(curr_sum)

        for it in range(nmb_iters):
            u = curr_sum
            Q *= (r / u).unsqueeze(1)
            Q *= (c / torch.sum(Q, dim=0)).unsqueeze(0)
            curr_sum = torch.sum(Q, dim=1)
            dist.all_reduce(curr_sum)
        return (Q / torch.sum(Q, dim=0, keepdim=True)).t().float()

# Cell
class SwAV(Callback):
    def __init__(self, crop_sizes=[224,96],
                       num_crops=[2,6],
                       min_scales=[0.14,0.05],
                       max_scales=[1.,0.14],
                       crop_assgn_ids=[0,1],
                 **aug_kwargs):

        store_attr('crop_assgn_ids')
        self.augs = []
        for nc, size, mins, maxs in zip(num_crops, crop_sizes, min_scales, max_scales):
            self.augs += [get_aug_pipe(size, mins, maxs, **aug_kwargs) ]*nc




    def before_fit(self):
        self.old_lf = self.learn.loss_func
        self.old_met = self.learn.metrics
        self.learn.metrics = []
        self.learn.loss_func = SimCLRLoss(self.temp)

    def before_batch(self):
        "Generate multi crop augmentations"
        self.learn.xb = ([aug(self.x) for aug in self.augs],)


    def after_fit(self):
        self.learn.loss_fun = self.old_lf
        self.learn.metrics = self.old_met

    def show_one(self):
        xb = self.learn.xb[0]
        bs = len(xb)//2
        b1 = self.aug1.decode(to_detach(xb[:bs]))
        b2 = self.aug2.decode(to_detach(xb[bs:]))
        i = np.random.choice(len(b1))
        show_images([b1[i], b2[i]], nrows=1, ncols=2)