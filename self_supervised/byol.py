# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/10-byol.ipynb (unless otherwise specified).

__all__ = ['get_aug_pipe', 'create_encoder', 'MLP', 'BYOLModel', 'create_byol_model', 'cosine_similarity',
           'symmetric_mse_loss', 'byol_loss', 'BYOL']

# Cell
from fastai.vision.all import *
import kornia
import copy

# Cell
def get_aug_pipe(size, stats=imagenet_stats, s=.6, xtra_tfms=[]):
    "SimCLR augmentations"
    rrc = kornia.augmentation.RandomResizedCrop((size, size), scale=(0.2, 1.0), ratio=(3/4, 4/3))
    rhf = kornia.augmentation.RandomHorizontalFlip()
    rcj = kornia.augmentation.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)
    rgs = kornia.augmentation.RandomGrayscale(p=0.2)

    tfms = [rrc, rhf, rcj, rgs, Normalize.from_stats(*stats)]
    pipe = Pipeline(tfms + xtra_tfms)
    pipe.split_idx = 0
    return pipe

# Cell
def create_encoder(arch, n_in=3, pretrained=True, cut=None, concat_pool=True):
    "Create encoder from a given arch backbone"
    encoder = create_body(arch, n_in, pretrained, cut)
    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)
    return nn.Sequential(*encoder, pool, Flatten())

# Cell
class MLP(Module):
    "MLP module as described in paper"
    def __init__(self, dim, projection_size=256, hidden_size=2048):
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_size, projection_size)
        )

    def forward(self, x):
        return self.net(x)

# Cell
class BYOLModel(Module):
    "Compute predictions of v1 and v2"
    def __init__(self,encoder,projector,predictor):
        self.encoder,self.projector,self.predictor = encoder,projector,predictor

    def forward(self,v1,v2):
        q1 = self.predictor(self.projector(self.encoder(v1)))
        q2 = self.predictor(self.projector(self.encoder(v2)))
        return (q1,q2)

# Cell
def create_byol_model(arch=resnet50, n_in=3, pretrained=True, cut=None, concat_pool=True,
                      hidden_size=4096, projection_size=256):
    encoder = create_encoder(arch, n_in, pretrained, cut, concat_pool)
    with torch.no_grad(): representation = encoder(torch.randn((2,3,128,128)))
    projector = MLP(representation.size(1), projection_size, hidden_size=hidden_size)
    predictor = MLP(projection_size, projection_size, hidden_size=hidden_size)
    apply_init(projector)
    apply_init(predictor)
    return BYOLModel(encoder, projector, predictor)

# Cell
def cosine_similarity(x1, x2=None, eps=1e-8):
    x2 = x1 if x2 is None else x2
    w1 = x1.norm(p=2, dim=1, keepdim=True)
    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)
    return torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)

# Cell
def _mse_loss(x, y):
    x = F.normalize(x, dim=-1, p=2)
    y = F.normalize(y, dim=-1, p=2)
    return 2 - 2 * (x * y).sum(dim=-1)

def symmetric_mse_loss(pred, *yb):
    (q1,q2),z1,z2 = pred,*yb
    return (_mse_loss(q1,z2) + _mse_loss(q2,z1)).mean()
byol_loss = symmetric_mse_loss

# Cell
class BYOL(Callback):
    "Implementation of https://arxiv.org/pdf/2006.07733.pdf"
    def __init__(self, T=0.99, debug=True, size=224, **aug_kwargs):
        self.T, self.debug = T, debug
        self.aug1 = get_aug_pipe(size, **aug_kwargs)
        self.aug2 = get_aug_pipe(size, **aug_kwargs)


    def before_fit(self):
        "Create target model"
        self.target_model = copy.deepcopy(self.learn.model).to(self.dls.device)
        self.T_sched = SchedCos(self.T, 1)


    def before_batch(self):
        "Generate 2 views of the same image and calculate target projections for these views"
        if self.debug: print(f"self.x[0]: {self.x[0]}")

        v1,v2 = self.aug1(self.x), self.aug2(self.x.clone())
        self.learn.xb = (v1,v2)

        if self.debug:
            print(f"v1[0]: {v1[0]}\nv2[0]: {v2[0]}")
            self.show_one()
            assert not torch.equal(*self.learn.xb)

        with torch.no_grad():
            z1 = self.target_model.projector(self.target_model.encoder(v1))
            z2 = self.target_model.projector(self.target_model.encoder(v2))
            self.learn.yb = (z1,z2)


    def after_step(self):
        "Update target model and T"
        self.T = self.T_sched(self.pct_train)
        with torch.no_grad():
            for param_k, param_q in zip(self.target_model.parameters(), self.model.parameters()):
                param_k.data = param_k.data * self.T + param_q.data * (1. - self.T)


    def show_one(self):
        b1 = self.aug1.decode(to_detach(self.learn.xb[0]))
        b2 = self.aug1.decode(to_detach(self.learn.xb[1]))
        i = np.random.choice(len(b1))
        show_images([b1[i],b2[i]], nrows=1, ncols=2)